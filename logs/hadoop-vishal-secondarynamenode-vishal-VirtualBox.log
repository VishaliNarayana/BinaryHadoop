2016-03-18 16:38:03,964 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-18 16:38:04,016 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-18 16:38:05,451 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-18 16:38:05,595 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-18 16:38:05,595 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-18 16:38:05,934 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 3191@vishal-VirtualBox
2016-03-18 16:38:05,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-18 16:38:05,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-18 16:38:06,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-18 16:38:06,044 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-18 16:38:06,046 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-18 16:38:06,047 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 18 16:38:06
2016-03-18 16:38:06,050 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-18 16:38:06,050 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-18 16:38:06,051 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-18 16:38:06,051 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-18 16:38:06,087 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-18 16:38:06,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-18 16:38:06,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-18 16:38:06,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-18 16:38:06,094 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-18 16:38:06,094 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-18 16:38:06,094 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-18 16:38:06,094 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-18 16:38:06,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-18 16:38:06,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-18 16:38:06,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-18 16:38:06,096 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-18 16:38:06,103 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-18 16:38:06,405 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-18 16:38:06,405 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-18 16:38:06,410 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-18 16:38:06,410 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-18 16:38:06,423 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-18 16:38:06,423 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-18 16:38:06,423 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-18 16:38:06,423 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-18 16:38:06,434 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-18 16:38:06,434 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-18 16:38:06,435 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-18 16:38:06,435 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-18 16:38:06,436 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-18 16:38:06,441 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-18 16:38:06,441 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-18 16:38:06,444 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-18 16:38:06,444 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-18 16:38:06,444 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-18 16:38:06,467 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-18 16:38:06,783 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-18 16:38:06,805 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-18 16:38:06,820 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-18 16:38:06,835 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-18 16:38:06,853 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-18 16:38:06,854 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-18 16:38:06,854 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-18 16:38:06,946 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-18 16:38:06,949 INFO org.mortbay.log: jetty-6.1.26
2016-03-18 16:38:07,424 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-18 16:38:07,424 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-18 16:38:07,451 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-18 16:38:07,451 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-18 16:39:07,875 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2016-03-18 16:39:08,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=188&storageInfo=-63:1694055830:0:CID-5b16bd21-1c10-4191-8c63-3d9863731959
2016-03-18 16:39:08,348 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2016-03-18 16:39:08,933 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.21s at 9.39 KB/s
2016-03-18 16:39:08,933 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000188 size 2333 bytes.
2016-03-18 16:39:08,959 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=189&endTxId=190&storageInfo=-63:1694055830:0:CID-5b16bd21-1c10-4191-8c63-3d9863731959
2016-03-18 16:39:08,975 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2016-03-18 16:39:08,975 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000189-0000000000000000190_0000000000010483692 size 0 bytes.
2016-03-18 16:39:09,075 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 26 INodes.
2016-03-18 16:39:09,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-03-18 16:39:09,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 188 from /tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000188
2016-03-18 16:39:09,119 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-03-18 16:39:09,130 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-18 16:39:09,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000189-0000000000000000190 expecting start txid #189
2016-03-18 16:39:09,141 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000189-0000000000000000190
2016-03-18 16:39:09,155 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000189-0000000000000000190 of size 42 edits # 2 loaded in 0 seconds
2016-03-18 16:39:09,246 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-vishal/dfs/namesecondary
2016-03-18 16:39:09,371 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 190 to namenode at http://localhost:50070 in 0.112 seconds
2016-03-18 16:39:09,372 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2333
2016-03-18 17:39:10,348 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2016-03-18 17:39:10,348 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=191&endTxId=192&storageInfo=-63:1694055830:0:CID-5b16bd21-1c10-4191-8c63-3d9863731959
2016-03-18 17:39:10,356 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-03-18 17:39:10,356 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000191-0000000000000000192_0000000000014085082 size 0 bytes.
2016-03-18 17:39:10,356 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-18 17:39:10,356 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000191-0000000000000000192 expecting start txid #191
2016-03-18 17:39:10,356 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000191-0000000000000000192
2016-03-18 17:39:10,357 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000191-0000000000000000192 of size 42 edits # 2 loaded in 0 seconds
2016-03-18 17:39:10,372 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 190
2016-03-18 17:39:10,373 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000188, cpktTxId=0000000000000000188)
2016-03-18 17:39:10,392 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 192 to namenode at http://localhost:50070 in 0.014 seconds
2016-03-18 17:39:10,392 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2333
2016-03-18 18:39:11,274 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2016-03-18 18:39:11,275 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=193&endTxId=196&storageInfo=-63:1694055830:0:CID-5b16bd21-1c10-4191-8c63-3d9863731959
2016-03-18 18:39:11,284 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2016-03-18 18:39:11,284 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000193-0000000000000000196_0000000000017686009 size 0 bytes.
2016-03-18 18:39:11,285 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-18 18:39:11,285 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000193-0000000000000000196 expecting start txid #193
2016-03-18 18:39:11,285 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000193-0000000000000000196
2016-03-18 18:39:11,309 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000193-0000000000000000196 of size 166 edits # 4 loaded in 0 seconds
2016-03-18 18:39:11,336 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 192
2016-03-18 18:39:11,336 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000190, cpktTxId=0000000000000000190)
2016-03-18 18:39:11,365 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 196 to namenode at http://localhost:50070 in 0.026 seconds
2016-03-18 18:39:11,365 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2333
2016-03-18 19:39:12,124 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2016-03-18 19:39:12,124 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=197&endTxId=198&storageInfo=-63:1694055830:0:CID-5b16bd21-1c10-4191-8c63-3d9863731959
2016-03-18 19:39:12,130 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-03-18 19:39:12,130 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000197-0000000000000000198_0000000000021286858 size 0 bytes.
2016-03-18 19:39:12,131 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-18 19:39:12,131 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000197-0000000000000000198 expecting start txid #197
2016-03-18 19:39:12,131 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000197-0000000000000000198
2016-03-18 19:39:12,132 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000197-0000000000000000198 of size 42 edits # 2 loaded in 0 seconds
2016-03-18 19:39:12,141 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 196
2016-03-18 19:39:12,142 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000192, cpktTxId=0000000000000000192)
2016-03-18 19:39:12,163 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 198 to namenode at http://localhost:50070 in 0.017 seconds
2016-03-18 19:39:12,163 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2333
2016-03-18 19:54:36,511 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-18 19:54:36,532 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-18 19:54:37,679 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-18 19:54:37,844 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-18 19:54:37,844 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-18 19:54:38,091 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 5966@vishal-VirtualBox
2016-03-18 19:54:38,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-18 19:54:38,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-18 19:54:38,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-18 19:54:38,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-18 19:54:38,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-18 19:54:38,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 18 19:54:38
2016-03-18 19:54:38,171 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-18 19:54:38,171 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-18 19:54:38,172 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-18 19:54:38,172 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-18 19:54:38,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-18 19:54:38,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-18 19:54:38,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-18 19:54:38,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-18 19:54:38,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-18 19:54:38,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-18 19:54:38,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-18 19:54:38,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-18 19:54:38,242 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-18 19:54:38,242 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-18 19:54:38,242 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-18 19:54:38,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-18 19:54:38,252 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-18 19:54:38,806 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-18 19:54:38,806 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-18 19:54:38,806 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-18 19:54:38,806 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-18 19:54:38,817 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-18 19:54:38,817 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-18 19:54:38,817 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-18 19:54:38,817 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-18 19:54:38,831 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-18 19:54:38,832 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-18 19:54:38,832 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-18 19:54:38,832 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-18 19:54:38,839 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-18 19:54:38,839 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-18 19:54:38,839 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-18 19:54:38,843 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-18 19:54:38,843 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-18 19:54:38,843 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-18 19:54:38,865 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-18 19:54:38,995 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-18 19:54:39,010 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-18 19:54:39,017 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-18 19:54:39,024 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-18 19:54:39,032 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-18 19:54:39,032 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-18 19:54:39,032 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-18 19:54:39,070 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-18 19:54:39,083 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-18 19:54:39,087 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2016-03-18 19:54:39,088 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-18 20:39:13,045 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Found no edit logs to download on NN since txid 198
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:432)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:40:13,260 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:41:13,359 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:42:13,463 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:43:13,525 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:44:13,656 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:45:13,909 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:46:14,071 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:47:14,198 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:48:14,305 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:49:14,407 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:50:14,490 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:51:14,584 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:52:14,675 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:53:14,812 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:54:14,928 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:55:15,044 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:56:15,164 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:57:15,281 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:58:15,347 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 20:59:15,408 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:00:15,475 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:01:15,535 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:02:15,564 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:03:15,653 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:04:15,741 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:05:15,807 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:06:15,868 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:07:15,914 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:08:15,985 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:09:16,061 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:10:16,095 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:11:16,161 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:12:16,230 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:13:16,328 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:14:16,411 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:15:16,487 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:16:16,584 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:17:16,679 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:18:16,740 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:19:16,789 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:20:16,920 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:21:16,962 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:22:17,147 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:23:17,229 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:24:17,333 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:25:17,392 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:26:17,514 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:27:17,624 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:28:17,731 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:29:17,790 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:30:17,863 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:31:17,929 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:32:17,979 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:33:18,031 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:34:18,169 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:35:18,234 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:36:18,291 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:37:18,356 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:38:18,405 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:39:18,506 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:40:18,590 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:41:18,676 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:42:18,814 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:43:19,010 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:44:19,066 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:45:19,136 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:46:19,219 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:47:19,279 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:48:19,406 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:49:19,500 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:50:19,567 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:51:19,680 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:52:19,727 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:53:19,815 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:54:19,898 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:55:19,952 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:56:20,038 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:57:20,185 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:58:20,279 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 21:59:20,389 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:00:20,460 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:01:20,547 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:02:20,705 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:03:20,838 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:04:20,989 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:05:21,090 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:06:21,230 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:07:21,425 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:08:21,524 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:09:21,577 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:10:21,640 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:11:21,689 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:12:21,792 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:13:21,852 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:14:21,881 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:15:21,909 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:16:21,977 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:17:22,076 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:18:22,133 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:19:22,168 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:20:22,198 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:21:22,233 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:22:22,287 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:23:22,349 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:24:22,536 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:25:22,628 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:26:22,691 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:27:22,785 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:28:22,892 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:29:22,981 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:30:23,072 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:31:23,219 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:32:23,359 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:33:23,419 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:34:23,490 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:35:23,568 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:36:23,689 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:37:23,799 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:38:23,876 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:39:23,936 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:40:24,033 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:41:24,130 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:42:24,252 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:43:24,383 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:44:24,495 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-18 22:45:26,253 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 09:24:29,924 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 09:25:30,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 09:26:30,194 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 09:27:30,298 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 09:28:30,395 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 09:29:30,481 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 09:30:30,539 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 09:31:30,640 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 199: [[311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368], [369,370], [371,372], [373,374], [375,376], [377,378], [379,380], [381,382], [383,384], [385,386], [387,388], [389,390], [391,392], [393,394], [395,396], [397,398], [399,400], [401,402], [403,404], [405,406], [407,408], [409,410], [411,412], [413,414], [415,416], [417,418], [419,420], [421,422], [423,424], [425,426], [427,428], [429,430], [431,432], [433,434], [435,436], [437,438], [439,440], [441,442], [443,444], [445,446], [447,448], [449,450], [451,452], [453,454], [455,456], [457,458], [459,460], [461,462], [463,464], [465,466], [467,468], [469,470], [471,472], [473,474], [475,476], [477,478], [479,480], [481,482], [483,484], [485,486], [487,488], [489,490], [491,492], [493,494], [495,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,526], [527,528], [529,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 09:31:56,356 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-19 09:31:56,380 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 17:39:29,706 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 17:39:29,768 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 17:39:30,902 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 17:39:31,082 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 17:39:31,083 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 17:39:31,522 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 3291@vishal-VirtualBox
2016-03-19 17:39:31,529 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 17:39:31,529 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 17:39:31,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 17:39:31,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 17:39:31,588 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 17:39:31,589 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 17:39:31
2016-03-19 17:39:31,598 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 17:39:31,598 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 17:39:31,600 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 17:39:31,600 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 17:39:31,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 17:39:31,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 17:39:31,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 17:39:31,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 17:39:31,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 17:39:31,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 17:39:31,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 17:39:31,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 17:39:31,645 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 17:39:31,645 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 17:39:31,645 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 17:39:31,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 17:39:31,653 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 17:39:32,015 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 17:39:32,016 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 17:39:32,019 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 17:39:32,019 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 17:39:32,032 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 17:39:32,033 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 17:39:32,033 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 17:39:32,033 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 17:39:32,054 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 17:39:32,054 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 17:39:32,054 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 17:39:32,054 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 17:39:32,084 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 17:39:32,084 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 17:39:32,084 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 17:39:32,087 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 17:39:32,088 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 17:39:32,088 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 17:39:32,171 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 17:39:32,518 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 17:39:32,547 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 17:39:32,575 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 17:39:32,596 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 17:39:32,614 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 17:39:32,614 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 17:39:32,614 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 17:39:32,689 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-19 17:39:32,697 INFO org.mortbay.log: jetty-6.1.26
2016-03-19 17:39:33,253 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-19 17:39:33,253 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-19 17:39:33,283 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-19 17:39:33,283 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-19 17:40:33,629 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2016-03-19 17:40:34,131 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:1604432663:0:CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27
2016-03-19 17:40:34,229 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2016-03-19 17:40:34,902 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.13s at 0.00 KB/s
2016-03-19 17:40:34,903 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 353 bytes.
2016-03-19 17:40:34,916 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-63:1604432663:0:CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27
2016-03-19 17:40:34,936 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-03-19 17:40:34,937 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000003783359 size 0 bytes.
2016-03-19 17:40:35,004 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-03-19 17:40:35,095 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-03-19 17:40:35,109 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000000
2016-03-19 17:40:35,109 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-03-19 17:40:35,115 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-19 17:40:35,123 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2016-03-19 17:40:35,123 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002
2016-03-19 17:40:35,166 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2016-03-19 17:40:35,243 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-vishal/dfs/namesecondary
2016-03-19 17:40:35,297 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://localhost:50070 in 0.041 seconds
2016-03-19 17:40:35,298 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 353
2016-03-19 18:40:35,897 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2016-03-19 18:40:35,898 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=3&endTxId=4&storageInfo=-63:1604432663:0:CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27
2016-03-19 18:40:35,903 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-03-19 18:40:35,904 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000004_0000000000007384342 size 0 bytes.
2016-03-19 18:40:35,905 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-19 18:40:35,905 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000004 expecting start txid #3
2016-03-19 18:40:35,905 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000004
2016-03-19 18:40:35,905 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000004 of size 42 edits # 2 loaded in 0 seconds
2016-03-19 18:40:35,922 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2016-03-19 18:40:35,922 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2016-03-19 18:40:35,942 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4 to namenode at http://localhost:50070 in 0.015 seconds
2016-03-19 18:40:35,942 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 353
2016-03-19 18:47:50,418 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-19 18:47:50,419 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 18:49:37,337 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 18:49:37,362 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 18:49:38,475 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 18:49:38,646 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 18:49:38,647 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 18:49:38,917 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 5584@vishal-VirtualBox
2016-03-19 18:49:39,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 18:49:39,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 18:49:39,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 18:49:39,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 18:49:39,096 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 18:49:39,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 18:49:39
2016-03-19 18:49:39,109 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 18:49:39,109 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 18:49:39,111 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 18:49:39,111 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 18:49:39,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 18:49:39,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 18:49:39,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 18:49:39,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 18:49:39,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 18:49:39,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 18:49:39,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 18:49:39,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 18:49:39,140 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 18:49:39,140 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 18:49:39,140 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 18:49:39,140 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 18:49:39,143 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 18:49:39,507 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 18:49:39,507 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 18:49:39,508 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 18:49:39,508 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 18:49:39,508 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 18:49:39,509 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 18:49:39,509 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 18:49:39,509 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 18:49:39,529 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 18:49:39,529 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 18:49:39,529 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 18:49:39,529 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 18:49:39,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 18:49:39,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 18:49:39,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 18:49:39,545 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 18:49:39,545 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 18:49:39,545 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 18:49:39,572 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 18:49:39,687 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 18:49:39,694 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 18:49:39,699 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 18:49:39,706 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 18:49:39,714 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 18:49:39,714 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 18:49:39,714 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 18:49:39,743 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-19 18:49:39,743 INFO org.mortbay.log: jetty-6.1.26
2016-03-19 18:49:40,037 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-19 18:49:40,037 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-19 18:49:40,063 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-19 18:49:40,063 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-19 18:50:40,469 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 18:51:40,512 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 18:52:40,607 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 18:53:40,697 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 18:54:40,772 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 18:55:40,853 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 18:56:40,942 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 18:57:41,025 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 18:58:41,061 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 18:59:41,095 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 19:00:41,140 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 19:01:41,257 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 19:02:41,370 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 19:03:41,424 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 998986866 cTime = 0 ; clusterId = CID-f295bf43-bd22-4923-a78a-de9cea3b0fb0 ; blockpoolId = BP-538491122-127.0.1.1-1458431351810.
Expecting respectively: -63; 1604432663; 0; CID-4b8e6da6-a432-4c7c-9867-eaa6c7a12a27; BP-1163673378-127.0.1.1-1458427136377.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 19:04:24,708 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-19 19:04:24,709 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 19:10:42,687 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 19:10:42,754 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 19:10:43,979 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 19:10:44,161 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 19:10:44,162 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 19:10:44,755 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 2952@vishal-VirtualBox
2016-03-19 19:10:44,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 19:10:44,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 19:10:44,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 19:10:44,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 19:10:44,850 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 19:10:44,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 19:10:44
2016-03-19 19:10:44,855 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 19:10:44,856 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:10:44,869 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 19:10:44,869 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 19:10:44,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 19:10:44,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 19:10:44,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 19:10:44,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 19:10:44,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 19:10:44,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 19:10:44,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 19:10:44,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 19:10:44,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 19:10:44,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 19:10:44,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 19:10:44,925 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 19:10:44,929 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 19:10:45,403 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 19:10:45,403 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:10:45,404 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 19:10:45,404 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 19:10:45,418 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 19:10:45,418 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 19:10:45,418 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 19:10:45,418 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 19:10:45,436 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 19:10:45,436 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:10:45,437 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 19:10:45,437 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 19:10:45,438 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 19:10:45,442 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 19:10:45,442 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 19:10:45,450 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 19:10:45,450 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 19:10:45,450 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 19:10:45,497 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 19:10:45,677 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 19:10:45,696 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 19:10:45,708 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 19:10:45,755 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 19:10:45,775 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 19:10:45,775 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 19:10:45,775 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 19:10:45,963 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-19 19:10:45,967 INFO org.mortbay.log: jetty-6.1.26
2016-03-19 19:10:46,586 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-19 19:10:46,586 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-19 19:10:46,622 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-19 19:10:46,622 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-19 19:11:47,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:11:48,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:11:49,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:11:50,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:11:51,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:11:52,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:11:53,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:11:54,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:11:55,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:11:56,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:11:56,743 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 19:12:57,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:12:58,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:12:59,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:13:00,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:13:01,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:13:02,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:13:03,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:13:04,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:13:05,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:13:06,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:13:06,762 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 19:14:07,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:14:08,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:14:09,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:14:10,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:14:11,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:14:12,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:14:13,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:14:14,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:14:15,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:14:16,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:14:16,780 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 19:15:16,651 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-19 19:15:16,652 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 19:15:56,247 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 19:15:56,268 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 19:15:57,519 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 19:15:57,721 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 19:15:57,721 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 19:15:58,035 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 5330@vishal-VirtualBox
2016-03-19 19:15:58,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 19:15:58,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 19:15:58,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 19:15:58,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 19:15:58,115 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 19:15:58,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 19:15:58
2016-03-19 19:15:58,127 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 19:15:58,127 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:15:58,129 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 19:15:58,129 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 19:15:58,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 19:15:58,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 19:15:58,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 19:15:58,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 19:15:58,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 19:15:58,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 19:15:58,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 19:15:58,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 19:15:58,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 19:15:58,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 19:15:58,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 19:15:58,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 19:15:58,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 19:15:58,546 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 19:15:58,546 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:15:58,566 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 19:15:58,566 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 19:15:58,576 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 19:15:58,576 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 19:15:58,576 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 19:15:58,576 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 19:15:58,604 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 19:15:58,604 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:15:58,604 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 19:15:58,604 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 19:15:58,614 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 19:15:58,614 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 19:15:58,614 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 19:15:58,617 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 19:15:58,617 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 19:15:58,617 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 19:15:58,642 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 19:15:58,797 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 19:15:58,812 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 19:15:58,825 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 19:15:58,835 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 19:15:58,844 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 19:15:58,856 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 19:15:58,856 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 19:15:58,895 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-19 19:15:58,895 INFO org.mortbay.log: jetty-6.1.26
2016-03-19 19:15:59,239 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-19 19:15:59,239 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-19 19:15:59,258 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-19 19:15:59,258 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-19 19:17:00,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:17:01,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:17:02,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:17:03,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:17:04,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:17:05,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:17:06,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:17:07,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:17:08,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:17:09,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:17:09,459 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 19:17:31,649 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-19 19:17:31,656 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 19:20:32,329 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 19:20:32,458 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 19:20:36,988 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 19:20:37,564 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 19:20:37,564 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 19:20:38,533 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 2787@vishal-VirtualBox
2016-03-19 19:20:38,566 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 19:20:38,566 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 19:20:38,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 19:20:38,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 19:20:38,858 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 19:20:38,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 19:20:38
2016-03-19 19:20:38,893 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 19:20:38,893 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:20:38,894 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 19:20:38,894 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 19:20:39,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 19:20:39,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 19:20:39,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 19:20:39,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 19:20:39,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 19:20:39,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 19:20:39,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 19:20:39,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 19:20:39,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 19:20:39,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 19:20:39,051 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 19:20:39,051 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 19:20:39,070 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 19:20:40,512 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 19:20:40,513 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:20:40,513 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 19:20:40,513 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 19:20:40,542 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 19:20:40,542 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 19:20:40,542 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 19:20:40,542 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 19:20:40,587 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 19:20:40,587 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:20:40,588 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 19:20:40,588 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 19:20:40,604 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 19:20:40,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 19:20:40,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 19:20:40,608 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 19:20:40,608 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 19:20:40,608 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 19:20:40,718 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 19:20:41,311 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 19:20:41,397 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 19:20:41,409 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 19:20:41,452 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 19:20:41,485 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 19:20:41,485 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 19:20:41,485 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 19:20:41,707 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-19 19:20:41,721 INFO org.mortbay.log: jetty-6.1.26
2016-03-19 19:20:42,924 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-19 19:20:42,924 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-19 19:20:43,013 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-19 19:20:43,014 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-19 19:26:07,594 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-19 19:26:07,608 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 19:30:27,052 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 19:30:27,181 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 19:30:30,520 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 19:30:31,146 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 19:30:31,153 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 19:30:32,554 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 2699@vishal-VirtualBox
2016-03-19 19:30:32,582 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 19:30:32,583 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 19:30:32,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 19:30:32,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 19:30:32,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 19:30:32,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 19:30:32
2016-03-19 19:30:32,884 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 19:30:32,884 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:30:32,890 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 19:30:32,891 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 19:30:33,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 19:30:33,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 19:30:33,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 19:30:33,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 19:30:33,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 19:30:33,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 19:30:33,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 19:30:33,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 19:30:33,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 19:30:33,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 19:30:33,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 19:30:33,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 19:30:33,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 19:30:34,713 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 19:30:34,713 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:30:34,714 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 19:30:34,714 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 19:30:34,747 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 19:30:34,747 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 19:30:34,747 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 19:30:34,747 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 19:30:34,822 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 19:30:34,822 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:30:34,823 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 19:30:34,823 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 19:30:34,824 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 19:30:34,845 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 19:30:34,845 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 19:30:34,891 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 19:30:34,891 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 19:30:34,891 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 19:30:35,036 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 19:30:35,778 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 19:30:35,854 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 19:30:35,872 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 19:30:35,921 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 19:30:35,957 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 19:30:35,957 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 19:30:35,957 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 19:30:36,151 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-19 19:30:36,161 INFO org.mortbay.log: jetty-6.1.26
2016-03-19 19:30:37,270 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-19 19:30:37,270 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-19 19:30:37,292 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-19 19:30:37,292 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-19 19:44:38,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:44:39,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:44:40,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:44:41,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 19:44:42,583 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-19 19:44:42,584 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 19:46:28,589 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 19:46:28,610 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 19:46:29,839 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 19:46:30,043 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 19:46:30,043 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 19:46:30,330 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 5469@vishal-VirtualBox
2016-03-19 19:46:30,339 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 19:46:30,339 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 19:46:30,400 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 19:46:30,400 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 19:46:30,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 19:46:30,404 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 19:46:30
2016-03-19 19:46:30,407 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 19:46:30,407 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:46:30,410 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 19:46:30,410 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 19:46:30,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 19:46:30,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 19:46:30,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 19:46:30,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 19:46:30,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 19:46:30,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 19:46:30,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 19:46:30,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 19:46:30,453 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 19:46:30,453 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 19:46:30,453 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 19:46:30,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 19:46:30,461 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 19:46:30,848 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 19:46:30,848 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:46:30,862 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 19:46:30,862 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 19:46:30,891 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 19:46:30,892 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 19:46:30,892 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 19:46:30,892 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 19:46:30,910 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 19:46:30,910 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:46:30,910 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 19:46:30,910 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 19:46:30,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 19:46:30,919 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 19:46:30,919 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 19:46:30,922 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 19:46:30,922 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 19:46:30,922 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 19:46:30,953 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 19:46:31,117 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 19:46:31,135 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 19:46:31,141 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 19:46:31,159 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 19:46:31,170 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 19:46:31,170 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 19:46:31,171 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 19:46:31,209 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-19 19:46:31,209 INFO org.mortbay.log: jetty-6.1.26
2016-03-19 19:46:31,528 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-19 19:46:31,529 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-19 19:46:31,551 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-19 19:46:31,552 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-19 19:50:54,748 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 19:50:54,774 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 19:50:56,119 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 19:50:56,308 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 19:50:56,309 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 19:50:56,708 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 6127@vishal-VirtualBox
2016-03-19 19:50:56,717 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 19:50:56,717 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 19:50:56,782 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 19:50:56,782 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 19:50:56,784 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 19:50:56,786 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 19:50:56
2016-03-19 19:50:56,789 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 19:50:56,789 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:50:56,791 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 19:50:56,791 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 19:50:56,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 19:50:56,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 19:50:56,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 19:50:56,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 19:50:56,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 19:50:56,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 19:50:56,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 19:50:56,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 19:50:56,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 19:50:56,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 19:50:56,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 19:50:56,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 19:50:56,831 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 19:50:57,259 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 19:50:57,260 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:50:57,262 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 19:50:57,262 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 19:50:57,274 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 19:50:57,274 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 19:50:57,274 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 19:50:57,274 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 19:50:57,290 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 19:50:57,290 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:50:57,290 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 19:50:57,290 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 19:50:57,293 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 19:50:57,293 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 19:50:57,293 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 19:50:57,299 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 19:50:57,299 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 19:50:57,299 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 19:50:57,332 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 19:50:57,500 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 19:50:57,518 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 19:50:57,531 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 19:50:57,538 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 19:50:57,546 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 19:50:57,546 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 19:50:57,546 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 19:50:57,587 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 19:50:57,609 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 19:50:57,611 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2016-03-19 19:50:57,613 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 19:51:53,228 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 19:51:53,250 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 19:51:54,898 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 19:51:55,070 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 19:51:55,071 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 19:51:55,341 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 7042@vishal-VirtualBox
2016-03-19 19:51:55,349 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 19:51:55,349 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 19:51:55,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 19:51:55,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 19:51:55,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 19:51:55,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 19:51:55
2016-03-19 19:51:55,421 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 19:51:55,421 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:51:55,423 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 19:51:55,423 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 19:51:55,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 19:51:55,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 19:51:55,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 19:51:55,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 19:51:55,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 19:51:55,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 19:51:55,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 19:51:55,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 19:51:55,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 19:51:55,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 19:51:55,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 19:51:55,459 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 19:51:55,461 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 19:51:56,049 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 19:51:56,049 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:51:56,057 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 19:51:56,057 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 19:51:56,073 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 19:51:56,073 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 19:51:56,074 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 19:51:56,074 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 19:51:56,108 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 19:51:56,109 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:51:56,109 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 19:51:56,109 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 19:51:56,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 19:51:56,125 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 19:51:56,125 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 19:51:56,144 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 19:51:56,144 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 19:51:56,144 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 19:51:56,201 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 19:51:56,524 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 19:51:56,576 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 19:51:56,601 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 19:51:56,625 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 19:51:56,636 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 19:51:56,636 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 19:51:56,636 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 19:51:56,735 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 19:51:56,770 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 19:51:56,771 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2016-03-19 19:51:56,785 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 19:54:09,782 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 19:54:09,805 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 19:54:12,037 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 19:54:12,241 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 19:54:12,241 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 19:54:12,584 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 8503@vishal-VirtualBox
2016-03-19 19:54:12,592 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 19:54:12,592 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 19:54:12,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 19:54:12,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 19:54:12,659 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 19:54:12,663 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 19:54:12
2016-03-19 19:54:12,666 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 19:54:12,666 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:54:12,668 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 19:54:12,668 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 19:54:12,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 19:54:12,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 19:54:12,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 19:54:12,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 19:54:12,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 19:54:12,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 19:54:12,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 19:54:12,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 19:54:12,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 19:54:12,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 19:54:12,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 19:54:12,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 19:54:12,732 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 19:54:13,566 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 19:54:13,566 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:54:13,580 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 19:54:13,580 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 19:54:13,613 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 19:54:13,613 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 19:54:13,613 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 19:54:13,614 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 19:54:13,648 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 19:54:13,648 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:54:13,653 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 19:54:13,653 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 19:54:13,654 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 19:54:13,654 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 19:54:13,654 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 19:54:13,668 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 19:54:13,677 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 19:54:13,677 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 19:54:13,740 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 19:54:14,140 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 19:54:14,175 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 19:54:14,183 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 19:54:14,202 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 19:54:14,226 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 19:54:14,227 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 19:54:14,227 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 19:54:14,322 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 19:54:14,372 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 19:54:14,374 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2016-03-19 19:54:14,380 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 19:55:11,770 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 19:55:11,794 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 19:55:15,195 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 19:55:15,551 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 19:55:15,553 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 19:55:16,281 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 9365@vishal-VirtualBox
2016-03-19 19:55:16,295 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 19:55:16,295 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 19:55:16,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 19:55:16,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 19:55:16,457 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 19:55:16,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 19:55:16
2016-03-19 19:55:16,485 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 19:55:16,485 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:55:16,495 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 19:55:16,495 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 19:55:16,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 19:55:16,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 19:55:16,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 19:55:16,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 19:55:16,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 19:55:16,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 19:55:16,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 19:55:16,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 19:55:16,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 19:55:16,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 19:55:16,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 19:55:16,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 19:55:16,579 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 19:55:17,424 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 19:55:17,424 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:55:17,445 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 19:55:17,445 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 19:55:17,458 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 19:55:17,458 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 19:55:17,458 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 19:55:17,458 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 19:55:17,486 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 19:55:17,486 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:55:17,486 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 19:55:17,487 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 19:55:17,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 19:55:17,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 19:55:17,509 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 19:55:17,514 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 19:55:17,514 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 19:55:17,514 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 19:55:17,582 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 19:55:17,918 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 19:55:17,956 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 19:55:17,982 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 19:55:18,010 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 19:55:18,016 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 19:55:18,020 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 19:55:18,020 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 19:55:18,164 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 19:55:18,232 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 19:55:18,236 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2016-03-19 19:55:18,245 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 19:56:22,627 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 19:56:22,654 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 19:56:24,981 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 19:56:25,160 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 19:56:25,160 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 19:56:25,449 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 10853@vishal-VirtualBox
2016-03-19 19:56:25,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 19:56:25,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 19:56:25,541 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 19:56:25,541 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 19:56:25,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 19:56:25,552 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 19:56:25
2016-03-19 19:56:25,571 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 19:56:25,571 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:56:25,583 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 19:56:25,583 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 19:56:25,639 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 19:56:25,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 19:56:25,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 19:56:25,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 19:56:25,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 19:56:25,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 19:56:25,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 19:56:25,640 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 19:56:25,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 19:56:25,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 19:56:25,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 19:56:25,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 19:56:25,655 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 19:56:26,688 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 19:56:26,688 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:56:26,689 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 19:56:26,689 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 19:56:26,717 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 19:56:26,717 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 19:56:26,717 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 19:56:26,717 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 19:56:26,755 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 19:56:26,755 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 19:56:26,755 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 19:56:26,755 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 19:56:26,773 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 19:56:26,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 19:56:26,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 19:56:26,790 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 19:56:26,790 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 19:56:26,790 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 19:56:26,840 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 19:56:27,185 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 19:56:27,226 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 19:56:27,243 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 19:56:27,267 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 19:56:27,292 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 19:56:27,292 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 19:56:27,293 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 19:56:27,422 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 19:56:27,463 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 19:56:27,468 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2016-03-19 19:56:27,469 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 20:28:32,093 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1327)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5828)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1121)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:142)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:29:32,117 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1327)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5828)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1121)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:142)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:30:32,126 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1327)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5828)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1121)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:142)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:31:32,138 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Log not rolled. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1327)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5828)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1121)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:142)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12025)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.call(Client.java:1475)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:148)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:512)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:32:32,280 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Found no edit logs to download on NN since txid 0
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:432)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:33:32,416 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Found no edit logs to download on NN since txid 0
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:432)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:33:37,769 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 20:33:37,790 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 20:33:39,078 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 20:33:39,273 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 20:33:39,273 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 20:33:39,655 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 12909@vishal-VirtualBox
2016-03-19 20:33:39,663 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 20:33:39,664 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 20:33:39,732 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 20:33:39,732 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 20:33:39,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 20:33:39,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 20:33:39
2016-03-19 20:33:39,746 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 20:33:39,746 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 20:33:39,748 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 20:33:39,748 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 20:33:39,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 20:33:39,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 20:33:39,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 20:33:39,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 20:33:39,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 20:33:39,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 20:33:39,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 20:33:39,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 20:33:39,793 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 20:33:39,793 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 20:33:39,793 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 20:33:39,793 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 20:33:39,803 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 20:33:40,219 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 20:33:40,219 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 20:33:40,227 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 20:33:40,227 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 20:33:40,244 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 20:33:40,244 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 20:33:40,244 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 20:33:40,244 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 20:33:40,256 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 20:33:40,256 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 20:33:40,257 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 20:33:40,257 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 20:33:40,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 20:33:40,264 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 20:33:40,264 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 20:33:40,271 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 20:33:40,271 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 20:33:40,271 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 20:33:40,293 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 20:33:40,454 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 20:33:40,472 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 20:33:40,480 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 20:33:40,489 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 20:33:40,499 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 20:33:40,499 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 20:33:40,524 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 20:33:40,578 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 20:33:40,594 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 20:33:40,596 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2016-03-19 20:33:40,601 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 20:34:28,833 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 20:34:28,854 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 20:34:30,091 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 20:34:30,261 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 20:34:30,261 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 20:34:30,602 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 13771@vishal-VirtualBox
2016-03-19 20:34:30,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 20:34:30,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 20:34:30,678 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 20:34:30,678 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 20:34:30,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 20:34:30,681 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 20:34:30
2016-03-19 20:34:30,693 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 20:34:30,694 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 20:34:30,695 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 20:34:30,695 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 20:34:30,724 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 20:34:30,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 20:34:30,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 20:34:30,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 20:34:30,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 20:34:30,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 20:34:30,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 20:34:30,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 20:34:30,728 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 20:34:30,728 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 20:34:30,728 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 20:34:30,728 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 20:34:30,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 20:34:31,163 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 20:34:31,163 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 20:34:31,166 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 20:34:31,166 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 20:34:31,184 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 20:34:31,184 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 20:34:31,184 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 20:34:31,184 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 20:34:31,207 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 20:34:31,207 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 20:34:31,207 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 20:34:31,207 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 20:34:31,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 20:34:31,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 20:34:31,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 20:34:31,212 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 20:34:31,215 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 20:34:31,215 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 20:34:31,242 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 20:34:31,393 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 20:34:31,413 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 20:34:31,424 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 20:34:31,430 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 20:34:31,441 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 20:34:31,441 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 20:34:31,441 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 20:34:31,498 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 20:34:31,526 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 20:34:31,527 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2016-03-19 20:34:31,528 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 20:34:32,507 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Found no edit logs to download on NN since txid 0
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:432)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:35:32,624 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[38,39]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:36:32,669 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Found no edit logs to download on NN since txid 0
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:432)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:36:50,460 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 20:36:50,490 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 20:36:51,758 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 20:36:51,945 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 20:36:51,946 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 20:36:52,285 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 15285@vishal-VirtualBox
2016-03-19 20:36:52,296 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 20:36:52,296 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 20:36:52,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 20:36:52,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 20:36:52,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 20:36:52,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 20:36:52
2016-03-19 20:36:52,374 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 20:36:52,375 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 20:36:52,377 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 20:36:52,377 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 20:36:52,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 20:36:52,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 20:36:52,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 20:36:52,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 20:36:52,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 20:36:52,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 20:36:52,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 20:36:52,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 20:36:52,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 20:36:52,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 20:36:52,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 20:36:52,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 20:36:52,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 20:36:52,831 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 20:36:52,831 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 20:36:52,833 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 20:36:52,833 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 20:36:52,861 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 20:36:52,861 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 20:36:52,861 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 20:36:52,861 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 20:36:52,884 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 20:36:52,884 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 20:36:52,889 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 20:36:52,889 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 20:36:52,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 20:36:52,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 20:36:52,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 20:36:52,894 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 20:36:52,895 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 20:36:52,895 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 20:36:52,925 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 20:36:53,120 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 20:36:53,141 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 20:36:53,146 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 20:36:53,157 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 20:36:53,168 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 20:36:53,168 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 20:36:53,168 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 20:36:53,209 INFO org.apache.hadoop.http.HttpServer2: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 20:36:53,228 FATAL org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Failed to start secondary namenode
java.net.BindException: Port in use: 0.0.0.0:50090
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:919)
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:856)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:276)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:192)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:671)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216)
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:914)
	... 4 more
2016-03-19 20:36:53,230 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2016-03-19 20:36:53,235 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 20:37:32,704 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:38:34,753 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:39:34,792 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:40:34,823 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:41:34,937 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:42:35,012 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:43:35,047 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:44:35,121 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:45:35,232 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:46:35,261 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:47:35,350 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:48:35,441 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:49:35,477 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:50:35,507 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:51:35,535 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:52:35,567 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:53:35,593 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:54:35,624 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:55:35,724 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:56:35,754 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:57:35,784 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:58:35,885 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 20:59:35,916 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:00:35,946 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:01:36,022 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:02:36,103 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:03:36,153 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:04:36,233 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:05:36,305 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:06:36,346 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:07:36,407 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:08:36,470 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:09:36,510 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:10:36,541 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:11:36,594 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:12:36,637 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:13:36,709 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:14:36,809 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:15:36,853 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:16:36,907 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:17:36,948 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:18:36,979 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:19:37,026 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:20:37,063 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:21:37,137 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:22:37,164 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:23:37,285 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:24:37,319 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:25:37,373 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:26:37,407 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:27:37,481 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:28:37,521 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:29:37,613 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:30:37,667 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:31:37,772 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:32:37,833 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:33:37,900 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:34:37,959 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:35:38,041 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:36:38,072 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:37:38,721 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:38:39,203 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:39:39,277 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:40:39,316 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:41:39,350 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:42:39,471 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:43:39,545 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:44:39,593 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:45:39,618 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:46:39,718 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:47:39,747 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:48:39,814 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:49:39,848 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:50:39,902 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:51:39,933 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:52:39,968 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:53:39,995 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:54:40,028 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:55:40,065 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:56:40,140 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:57:40,189 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:58:40,229 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 21:59:40,265 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:00:40,293 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:01:40,400 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:02:40,436 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:03:40,511 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:04:40,555 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:05:40,719 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:06:40,783 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:07:40,813 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:08:40,868 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:09:40,932 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:10:41,010 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:11:41,077 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:12:41,136 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:13:41,165 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:14:41,228 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:15:41,306 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:16:41,387 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:17:41,414 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:18:41,499 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:19:41,527 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:20:41,568 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:21:41,683 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:22:41,833 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:23:41,915 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:24:41,967 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:25:42,042 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:26:42,072 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:27:42,202 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:28:42,330 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:29:42,427 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:30:42,493 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:31:42,600 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:32:42,723 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:33:42,776 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:34:42,845 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 1: [[42,49], [50,93], [94,138], [139,140], [141,142], [143,144], [145,146], [147,148], [149,150], [151,152], [153,154], [155,156], [157,158], [159,160], [161,162], [163,164], [165,166], [167,168], [169,170], [171,172], [173,174], [175,176], [177,178], [179,180], [181,182], [183,184], [185,186], [187,188], [189,190], [191,192], [193,194], [195,196], [197,198], [199,200], [201,202], [203,204], [205,206], [207,208], [209,210], [211,212], [213,214], [215,216], [217,218], [219,220], [221,222], [223,224], [225,226], [227,228], [229,230], [231,232], [233,234], [235,236], [237,238], [239,240], [241,242], [243,244], [245,246], [247,248], [249,250], [251,252], [253,254], [255,256], [257,258], [259,260], [261,262], [263,264], [265,266], [267,268], [269,270], [271,272], [273,274], [275,276], [277,278], [279,280], [281,282], [283,284], [285,286], [287,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,346], [347,348], [349,350], [351,352], [353,354], [355,356], [357,358], [359,360], [361,362], [363,364], [365,366], [367,368]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-19 22:34:58,692 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-19 22:34:58,697 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-19 22:53:03,791 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-19 22:53:03,843 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-19 22:53:05,485 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-19 22:53:05,701 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-19 22:53:05,701 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-19 22:53:06,733 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 2834@vishal-VirtualBox
2016-03-19 22:53:06,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-19 22:53:06,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-19 22:53:06,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-19 22:53:06,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-19 22:53:06,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-19 22:53:06,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 19 22:53:06
2016-03-19 22:53:06,994 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-19 22:53:06,994 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 22:53:06,996 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-19 22:53:06,996 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-19 22:53:07,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-19 22:53:07,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-19 22:53:07,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-19 22:53:07,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-19 22:53:07,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-19 22:53:07,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-19 22:53:07,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-19 22:53:07,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-19 22:53:07,072 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-19 22:53:07,073 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-19 22:53:07,073 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-19 22:53:07,073 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-19 22:53:07,105 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-19 22:53:08,176 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-19 22:53:08,176 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 22:53:08,189 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-19 22:53:08,190 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-19 22:53:08,214 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-19 22:53:08,214 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-19 22:53:08,214 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-19 22:53:08,214 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-19 22:53:08,251 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-19 22:53:08,251 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-19 22:53:08,252 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-19 22:53:08,252 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-19 22:53:08,266 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-19 22:53:08,266 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-19 22:53:08,266 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-19 22:53:08,282 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-19 22:53:08,282 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-19 22:53:08,282 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-19 22:53:08,351 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-19 22:53:08,793 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-19 22:53:08,828 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-19 22:53:08,861 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-19 22:53:08,899 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-19 22:53:08,907 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-19 22:53:08,913 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-19 22:53:08,913 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-19 22:53:09,031 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-19 22:53:09,045 INFO org.mortbay.log: jetty-6.1.26
2016-03-19 22:53:09,862 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-19 22:53:09,862 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-19 22:53:09,923 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-19 22:53:09,923 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-19 22:54:11,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:54:12,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:54:13,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:54:14,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:54:15,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:54:16,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:54:17,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:54:18,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:54:19,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:54:20,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:54:20,088 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 22:55:21,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:55:22,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:55:23,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:55:24,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:55:25,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:55:26,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:55:27,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:55:28,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:55:29,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:55:30,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:55:30,106 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 22:56:31,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:56:32,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:56:33,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:56:34,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:56:35,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:56:36,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:56:37,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:56:38,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:56:39,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:56:40,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:56:40,120 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 22:57:41,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:57:42,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:57:43,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:57:44,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:57:45,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:57:46,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:57:47,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:57:48,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:57:49,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:57:50,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:57:50,143 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 22:58:51,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:58:52,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:58:53,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:58:54,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:58:55,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:58:56,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:58:57,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:58:58,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:58:59,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:59:00,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 22:59:00,180 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:00:01,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:00:02,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:00:03,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:00:04,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:00:05,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:00:06,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:00:07,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:00:08,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:00:09,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:00:10,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:00:10,195 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:01:11,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:01:12,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:01:13,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:01:14,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:01:15,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:01:16,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:01:17,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:01:18,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:01:19,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:01:20,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:01:20,208 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:02:21,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:02:22,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:02:23,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:02:24,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:02:25,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:02:26,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:02:27,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:02:28,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:02:29,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:02:30,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:02:30,221 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:03:31,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:03:32,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:03:33,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:03:34,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:03:35,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:03:36,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:03:37,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:03:38,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:03:39,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:03:40,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:03:40,232 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:04:41,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:04:42,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:04:43,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:04:44,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:04:45,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:04:46,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:04:47,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:04:48,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:04:49,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:04:50,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:04:50,244 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:05:51,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:05:52,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:05:53,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:05:54,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:05:55,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:05:56,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:05:57,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:05:58,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:05:59,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:06:00,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:06:00,260 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:07:01,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:07:02,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:07:03,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:07:04,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:07:05,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:07:06,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:07:07,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:07:08,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:07:09,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:07:10,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:07:10,278 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:08:11,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:08:12,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:08:13,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:08:14,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:08:15,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:08:16,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:08:17,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:08:18,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:08:19,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:08:20,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:08:20,295 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:09:21,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:09:22,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:09:23,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:09:24,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:09:25,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:09:26,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:09:27,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:09:28,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:09:29,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:09:30,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:09:30,304 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:10:31,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:10:32,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:10:33,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:10:34,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:10:35,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:10:36,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:10:37,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:10:38,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:10:39,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:10:40,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:10:40,315 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:11:41,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:11:42,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:11:43,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:11:44,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:11:45,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:11:46,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:11:47,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:11:48,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:11:49,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:11:50,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:11:50,335 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 18 more
2016-03-19 23:12:51,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:12:52,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:12:53,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:12:54,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:12:55,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:12:56,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:12:57,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:12:58,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:12:59,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:13:00,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:13:00,344 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:14:01,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:14:02,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:14:03,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:14:04,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:14:05,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:14:06,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:14:07,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:14:08,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:14:09,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:14:10,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:14:10,354 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:15:11,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:15:12,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:15:13,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:15:14,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:15:15,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:15:16,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:15:17,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:15:18,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:15:19,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:15:20,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:15:20,362 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:16:21,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:16:22,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:16:23,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:16:24,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:16:25,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:16:26,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:16:27,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:16:28,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:16:29,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:16:30,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:16:30,376 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:17:31,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:17:32,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:17:33,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:17:34,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:17:35,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:17:36,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:17:37,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:17:38,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:17:39,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:17:40,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:17:40,386 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:18:41,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:18:42,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:18:43,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:18:44,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:18:45,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:18:46,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:18:47,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:18:48,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:18:49,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:18:50,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:18:50,400 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:19:51,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:19:52,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:19:53,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:19:54,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:19:55,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:19:56,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:19:57,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:19:58,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:19:59,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:20:00,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:20:00,411 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:21:01,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:21:02,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:21:03,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:21:04,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:21:05,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:21:06,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:21:07,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:21:08,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:21:09,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:21:10,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:21:10,429 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:22:11,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:22:12,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:22:13,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:22:14,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:22:15,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:22:16,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:22:17,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:22:18,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:22:19,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:22:20,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:22:20,438 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:23:21,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:23:22,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:23:23,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:23:24,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:23:25,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:23:26,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:23:27,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:23:28,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:23:29,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:23:30,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:23:30,449 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:24:31,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:24:32,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:24:33,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:24:34,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:24:35,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:24:36,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:24:37,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:24:38,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:24:39,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:24:40,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:24:40,457 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:25:41,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:25:42,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:25:43,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:25:44,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:25:45,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:25:46,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:25:47,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:25:48,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:25:49,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:25:50,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:25:50,468 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:26:51,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:26:52,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:26:53,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:26:54,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:26:55,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:26:56,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:26:57,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:26:58,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:26:59,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:27:00,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:27:00,477 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:28:01,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:28:02,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:28:03,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:28:04,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:28:05,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:28:06,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:28:07,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:28:08,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:28:09,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:28:10,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:28:10,494 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:29:11,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:29:12,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:29:13,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:29:14,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:29:15,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:29:16,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:29:17,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:29:18,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:29:19,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:29:20,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:29:20,504 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:30:21,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:30:22,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:30:23,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:30:24,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:30:25,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:30:26,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:30:27,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:30:28,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:30:29,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:30:30,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:30:30,517 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:31:31,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:31:32,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:31:33,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:31:34,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:31:35,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:31:36,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:31:37,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:31:38,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:31:39,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:31:40,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:31:40,530 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:32:41,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:32:42,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:32:43,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:32:44,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:32:45,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:32:46,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:32:47,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:32:48,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:32:49,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:32:50,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:32:50,541 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:33:51,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:33:52,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:33:53,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:33:54,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:33:55,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:33:56,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:33:57,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:33:58,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:33:59,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:34:00,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:34:00,552 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:35:01,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:35:02,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:35:03,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:35:04,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:35:05,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:35:06,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:35:07,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:35:08,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:35:09,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:35:10,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:35:10,565 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:36:11,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:36:12,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:36:13,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:36:14,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:36:15,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:36:16,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:36:17,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:36:18,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:36:19,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:36:20,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:36:20,574 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:37:21,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:37:22,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:37:23,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:37:24,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:37:25,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:37:26,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:37:27,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:37:28,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:37:29,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:37:30,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:37:30,582 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:38:31,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:38:32,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:38:33,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:38:34,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:38:35,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:38:36,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:38:37,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:38:38,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:38:39,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:38:40,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:38:40,595 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:39:41,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:39:42,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:39:43,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:39:44,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:39:45,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:39:46,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:39:47,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:39:48,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:39:49,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:39:50,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:39:50,603 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:40:51,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:40:52,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:40:53,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:40:54,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:40:55,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:40:56,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:40:57,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:40:58,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:40:59,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:41:00,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:41:00,612 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:42:01,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:42:02,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:42:03,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:42:04,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:42:05,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:42:06,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:42:07,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:42:08,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:42:09,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:42:10,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:42:10,623 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:43:11,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:43:12,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:43:13,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:43:14,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:43:15,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:43:16,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:43:17,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:43:18,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:43:19,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:43:20,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:43:20,633 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:44:21,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:44:22,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:44:23,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:44:24,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:44:25,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:44:26,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:44:27,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:44:28,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:44:29,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:44:30,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:44:30,643 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:45:31,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:45:32,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:45:33,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:45:34,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:45:35,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:45:36,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:45:37,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:45:38,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:45:39,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:45:40,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:45:40,653 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:46:41,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:46:42,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:46:43,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:46:44,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:46:45,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:46:46,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:46:47,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:46:48,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:46:49,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:46:50,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:46:50,660 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:47:51,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:47:52,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:47:53,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:47:54,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:47:55,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:47:56,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:47:57,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:47:58,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:47:59,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:48:00,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:48:00,668 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:49:01,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:49:02,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:49:03,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:49:04,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:49:05,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:49:06,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:49:07,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:49:08,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:49:09,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:49:10,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:49:10,677 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:50:11,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:50:12,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:50:13,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:50:14,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:50:15,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:50:16,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:50:17,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:50:18,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:50:19,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:50:20,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:50:20,685 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:51:21,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:51:22,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:51:23,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:51:24,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:51:25,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:51:26,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:51:27,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:51:28,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:51:29,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:51:30,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:51:30,694 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:52:31,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:52:32,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:52:33,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:52:34,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:52:35,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:52:36,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:52:37,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:52:38,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:52:39,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:52:40,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:52:40,703 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:53:41,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:53:42,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:53:43,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:53:44,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:53:45,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:53:46,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:53:47,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:53:48,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:53:49,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:53:50,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:53:50,711 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:54:51,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:54:52,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:54:53,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:54:54,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:54:55,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:54:56,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:54:57,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:54:58,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:54:59,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:55:00,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:55:00,720 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:56:01,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:56:02,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:56:03,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:56:04,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:56:05,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:56:06,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:56:07,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:56:08,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:56:09,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:56:10,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:56:10,728 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:57:11,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:57:12,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:57:13,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:57:14,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:57:15,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:57:16,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:57:17,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:57:18,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:57:19,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:57:20,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:57:20,736 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:58:21,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:58:22,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:58:23,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:58:24,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:58:25,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:58:26,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:58:27,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:58:28,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:58:29,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:58:30,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:58:30,744 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-19 23:59:31,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:59:32,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:59:33,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:59:34,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:59:35,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:59:36,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:59:37,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:59:38,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:59:39,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:59:40,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-19 23:59:40,752 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:00:41,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:00:42,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:00:43,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:00:44,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:00:45,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:00:46,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:00:47,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:00:48,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:00:49,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:00:50,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:00:50,767 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:01:51,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:01:52,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:01:53,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:01:54,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:01:55,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:01:56,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:01:57,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:01:58,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:01:59,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:02:00,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:02:00,789 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:03:01,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:03:02,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:03:03,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:03:04,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:03:05,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:03:06,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:03:07,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:03:08,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:03:09,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:03:10,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:03:10,799 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:04:11,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:04:12,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:04:13,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:04:14,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:04:15,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:04:16,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:04:17,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:04:18,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:04:19,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:04:20,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:04:20,805 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:05:21,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:05:22,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:05:23,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:05:24,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:05:25,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:05:26,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:05:27,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:05:28,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:05:29,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:05:30,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:05:30,812 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:06:31,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:06:32,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:06:33,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:06:34,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:06:35,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:06:36,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:06:37,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:06:38,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:06:39,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:06:40,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:06:40,819 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:07:41,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:07:42,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:07:43,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:07:44,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:07:45,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:07:46,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:07:47,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:07:48,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:07:49,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:07:50,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:07:50,827 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:08:51,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:08:52,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:08:53,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:08:54,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:08:55,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:08:56,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:08:57,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:08:58,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:08:59,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:09:00,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:09:00,834 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:10:01,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:10:02,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:10:03,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:10:04,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:10:05,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:10:06,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:10:07,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:10:08,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:10:09,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:10:10,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:10:10,842 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:11:11,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:11:12,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:11:13,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:11:14,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:11:15,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:11:16,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:11:17,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:11:18,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:11:19,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:11:20,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:11:20,849 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:12:21,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:12:22,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:12:23,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:12:24,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:12:25,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:12:26,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:12:27,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:12:28,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:12:29,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:12:30,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:12:30,855 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:13:31,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:13:32,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:13:33,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:13:34,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:13:35,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:13:36,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:13:37,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:13:38,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:13:39,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:13:40,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:13:40,863 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:14:41,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:14:42,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:14:43,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:14:44,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:14:45,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:14:46,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:14:47,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:14:48,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:14:49,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:14:50,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:14:50,871 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:15:51,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:15:52,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:15:53,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:15:54,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:15:55,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:15:56,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:15:57,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:15:58,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:15:59,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:16:00,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:16:00,879 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:17:01,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:17:02,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:17:03,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:17:04,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:17:05,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:17:06,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:17:07,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:17:08,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:17:09,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:17:10,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:17:10,888 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:18:11,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:18:12,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:18:13,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:18:14,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:18:15,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:18:16,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:18:17,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:18:18,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:18:19,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:18:20,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:18:20,896 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:19:21,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:19:22,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:19:23,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:19:24,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:19:25,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:19:26,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:19:27,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:19:28,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:19:29,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:19:30,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:19:30,904 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:20:31,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:20:32,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:20:33,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:20:34,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:20:35,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:20:36,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:20:37,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:20:38,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:20:39,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:20:40,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:20:40,912 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:21:41,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:21:42,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:21:43,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:21:44,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:21:45,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:21:46,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:21:47,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:21:48,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:21:49,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:21:50,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:21:50,920 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:22:51,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:22:52,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:22:53,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:22:54,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:22:55,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:22:56,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:22:57,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:22:58,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:22:59,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:23:00,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:23:00,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:24:01,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:24:02,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:24:03,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:24:04,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:24:05,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:24:06,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:24:07,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:24:08,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:24:09,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:24:10,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:24:10,940 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:25:11,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:25:12,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:25:13,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:25:14,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:25:15,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:25:16,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:25:17,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:25:18,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:25:19,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:25:20,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:25:20,946 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:26:21,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:26:22,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:26:23,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:26:24,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:26:25,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:26:26,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:26:27,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:26:28,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:26:29,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:26:30,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:26:30,952 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:27:31,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:27:32,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:27:33,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:27:34,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:27:35,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:27:36,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:27:37,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:27:38,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:27:39,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:27:40,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:27:40,960 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:28:41,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:28:42,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:28:43,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:28:44,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:28:45,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:28:46,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:28:47,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:28:48,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:28:49,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:28:50,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:28:50,968 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:29:51,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:29:52,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:29:53,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:29:54,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:29:55,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:29:56,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:29:57,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:29:58,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:29:59,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:30:00,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:30:00,975 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:31:01,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:31:02,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:31:03,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:31:04,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:31:05,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:31:06,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:31:07,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:31:08,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:31:09,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:31:10,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:31:10,980 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:32:11,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:32:12,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:32:13,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:32:14,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:32:15,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:32:16,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:32:17,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:32:18,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:32:19,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:32:20,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:32:20,987 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:33:21,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:33:22,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:33:23,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:33:24,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:33:25,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:33:26,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:33:27,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:33:28,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:33:29,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:33:30,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:33:30,995 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:34:31,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:34:32,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:34:33,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:34:34,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:34:35,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:34:37,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:34:38,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:34:39,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:34:40,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:34:41,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:34:41,002 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:35:42,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:35:43,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:35:44,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:35:45,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:35:46,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:35:47,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:35:48,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:35:49,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:35:50,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:35:51,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:35:51,009 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:36:52,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:36:53,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:36:54,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:36:55,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:36:56,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:36:57,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:36:58,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:36:59,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:37:00,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:37:01,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:37:01,017 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:38:02,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:38:03,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:38:04,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:38:05,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:38:06,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:38:07,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:38:08,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:38:09,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:38:10,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:38:11,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:38:11,023 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:39:12,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:39:13,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:39:14,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:39:15,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:39:16,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:39:17,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:39:18,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:39:19,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:39:20,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:39:21,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:39:21,030 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:40:22,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:40:23,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:40:24,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:40:25,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:40:26,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:40:27,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:40:28,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:40:29,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:40:30,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:40:31,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:40:31,039 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:41:32,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:41:33,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:41:34,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:41:35,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:41:36,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:41:37,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:41:38,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:41:39,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:41:40,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:41:41,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:41:41,046 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:42:42,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:42:43,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:42:44,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:42:45,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:42:46,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:42:47,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:42:48,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:42:49,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:42:50,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:42:51,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:42:51,053 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:43:52,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:43:53,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:43:54,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:43:55,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:43:56,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:43:57,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:43:58,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:43:59,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:44:00,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:44:01,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:44:01,061 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:45:02,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:45:03,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:45:04,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:45:05,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:45:06,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:45:07,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:45:08,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:45:09,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:45:10,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:45:11,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:45:11,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:46:12,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:46:13,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:46:14,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:46:15,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:46:16,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:46:17,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:46:18,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:46:19,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:46:20,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:46:21,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:46:21,078 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:47:22,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:47:23,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:47:24,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:47:25,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:47:26,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:47:27,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:47:28,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:47:29,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:47:30,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:47:31,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:47:31,086 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:48:32,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:48:33,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:48:34,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:48:35,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:48:36,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:48:37,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:48:38,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:48:39,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:48:40,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:48:41,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:48:41,097 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:49:42,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:49:43,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:49:44,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:49:45,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:49:46,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:49:47,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:49:48,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:49:49,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:49:50,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:49:51,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:49:51,108 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:50:52,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:50:53,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:50:54,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:50:55,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:50:56,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:50:57,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:50:58,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:50:59,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:51:00,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:51:01,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:51:01,114 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:52:02,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:52:03,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:52:04,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:52:05,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:52:06,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:52:07,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:52:08,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:52:09,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:52:10,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:52:11,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:52:11,121 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:53:12,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:53:13,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:53:14,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:53:15,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:53:16,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:53:17,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:53:18,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:53:19,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:53:20,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:53:21,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:53:21,130 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:54:22,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:54:23,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:54:24,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:54:25,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:54:26,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:54:27,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:54:28,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:54:29,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:54:30,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:54:31,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-20 00:54:31,136 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor6.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-20 00:55:07,505 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-20 00:55:07,506 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-20 00:56:18,497 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-20 00:56:18,518 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-20 00:56:19,623 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-20 00:56:19,787 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-20 00:56:19,787 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-20 00:56:20,049 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 6755@vishal-VirtualBox
2016-03-20 00:56:20,057 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-20 00:56:20,057 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-20 00:56:20,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-20 00:56:20,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-20 00:56:20,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-20 00:56:20,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 20 00:56:20
2016-03-20 00:56:20,124 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-20 00:56:20,124 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-20 00:56:20,125 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-20 00:56:20,125 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-20 00:56:20,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-20 00:56:20,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-20 00:56:20,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-20 00:56:20,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-20 00:56:20,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-20 00:56:20,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-20 00:56:20,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-20 00:56:20,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-20 00:56:20,156 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-20 00:56:20,156 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-20 00:56:20,156 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-20 00:56:20,156 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-20 00:56:20,160 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-20 00:56:20,520 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-20 00:56:20,520 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-20 00:56:20,521 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-20 00:56:20,521 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-20 00:56:20,534 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-20 00:56:20,534 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-20 00:56:20,534 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-20 00:56:20,534 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-20 00:56:20,541 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-20 00:56:20,541 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-20 00:56:20,542 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-20 00:56:20,542 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-20 00:56:20,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-20 00:56:20,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-20 00:56:20,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-20 00:56:20,552 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-20 00:56:20,552 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-20 00:56:20,552 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-20 00:56:20,577 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-20 00:56:20,715 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-20 00:56:20,732 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-20 00:56:20,746 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-20 00:56:20,758 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-20 00:56:20,767 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-20 00:56:20,767 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-20 00:56:20,767 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-20 00:56:20,807 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-20 00:56:20,808 INFO org.mortbay.log: jetty-6.1.26
2016-03-20 00:56:21,103 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-20 00:56:21,103 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-20 00:56:21,125 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-20 00:56:21,125 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-20 00:57:21,703 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2016-03-20 00:57:22,674 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:851993283:0:CID-d96898ec-52b2-4521-8ac1-d6b10a73d42d
2016-03-20 00:57:22,938 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2016-03-20 00:57:24,230 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.23s at 0.00 KB/s
2016-03-20 00:57:24,230 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 353 bytes.
2016-03-20 00:57:24,259 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-63:851993283:0:CID-d96898ec-52b2-4521-8ac1-d6b10a73d42d
2016-03-20 00:57:24,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-03-20 00:57:24,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000008529801 size 0 bytes.
2016-03-20 00:57:24,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-03-20 00:57:24,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-03-20 00:57:24,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000000
2016-03-20 00:57:24,561 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-03-20 00:57:24,572 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-20 00:57:24,597 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2016-03-20 00:57:24,597 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002
2016-03-20 00:57:24,655 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2016-03-20 00:57:24,833 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-vishal/dfs/namesecondary
2016-03-20 00:57:24,933 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://localhost:50070 in 0.074 seconds
2016-03-20 00:57:24,933 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 353
2016-03-20 01:54:13,843 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-20 01:54:13,868 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-20 03:33:14,424 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-20 03:33:14,509 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-20 03:33:15,729 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-20 03:33:15,904 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-20 03:33:15,904 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-20 03:33:16,301 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 11866@vishal-VirtualBox
2016-03-20 03:33:16,310 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-20 03:33:16,310 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-20 03:33:16,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-20 03:33:16,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-20 03:33:16,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-20 03:33:16,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 20 03:33:16
2016-03-20 03:33:16,426 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-20 03:33:16,426 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-20 03:33:16,427 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-20 03:33:16,428 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-20 03:33:16,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-20 03:33:16,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-20 03:33:16,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-20 03:33:16,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-20 03:33:16,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-20 03:33:16,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-20 03:33:16,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-20 03:33:16,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-20 03:33:16,478 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-20 03:33:16,478 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-20 03:33:16,478 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-20 03:33:16,478 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-20 03:33:16,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-20 03:33:16,882 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-20 03:33:16,882 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-20 03:33:16,887 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-20 03:33:16,887 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-20 03:33:16,893 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-20 03:33:16,893 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-20 03:33:16,894 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-20 03:33:16,894 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-20 03:33:16,908 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-20 03:33:16,908 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-20 03:33:16,908 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-20 03:33:16,908 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-20 03:33:16,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-20 03:33:16,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-20 03:33:16,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-20 03:33:16,923 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-20 03:33:16,924 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-20 03:33:16,924 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-20 03:33:16,954 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-20 03:33:17,100 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-20 03:33:17,151 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-20 03:33:17,176 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-20 03:33:17,231 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-20 03:33:17,255 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-20 03:33:17,255 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-20 03:33:17,255 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-20 03:33:17,366 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-20 03:33:17,366 INFO org.mortbay.log: jetty-6.1.26
2016-03-20 03:33:18,015 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-20 03:33:18,015 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-20 03:33:18,050 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-20 03:33:18,050 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-20 03:34:18,525 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2016-03-20 03:34:19,125 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=3&storageInfo=-63:851993283:0:CID-d96898ec-52b2-4521-8ac1-d6b10a73d42d
2016-03-20 03:34:19,250 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2016-03-20 03:34:20,212 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.15s at 0.00 KB/s
2016-03-20 03:34:20,212 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000003 size 353 bytes.
2016-03-20 03:34:20,232 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=4&endTxId=10&storageInfo=-63:851993283:0:CID-d96898ec-52b2-4521-8ac1-d6b10a73d42d
2016-03-20 03:34:20,243 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2016-03-20 03:34:20,243 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000004-0000000000000000010_0000000000005832051 size 0 bytes.
2016-03-20 03:34:20,340 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-03-20 03:34:20,432 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-03-20 03:34:20,432 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 3 from /tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000003
2016-03-20 03:34:20,432 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-03-20 03:34:20,444 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-20 03:34:20,456 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000004-0000000000000000010 expecting start txid #4
2016-03-20 03:34:20,457 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000004-0000000000000000010
2016-03-20 03:34:20,536 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000004-0000000000000000010 of size 531 edits # 7 loaded in 0 seconds
2016-03-20 03:34:20,633 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-vishal/dfs/namesecondary
2016-03-20 03:34:20,711 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 10 to namenode at http://localhost:50070 in 0.062 seconds
2016-03-20 03:34:20,712 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 724
2016-03-20 03:55:46,071 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-20 03:55:46,097 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-20 22:50:01,464 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-20 22:50:01,500 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-20 22:50:02,470 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-20 22:50:02,640 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-20 22:50:02,640 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-20 22:50:02,900 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 5289@vishal-VirtualBox
2016-03-20 22:50:02,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-20 22:50:02,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-20 22:50:02,958 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-20 22:50:02,958 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-20 22:50:02,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-20 22:50:02,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 20 22:50:02
2016-03-20 22:50:02,964 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-20 22:50:02,964 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-20 22:50:02,965 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-20 22:50:02,965 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-20 22:50:03,003 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-20 22:50:03,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-20 22:50:03,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-20 22:50:03,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-20 22:50:03,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-20 22:50:03,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-20 22:50:03,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-20 22:50:03,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-20 22:50:03,012 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-20 22:50:03,013 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-20 22:50:03,013 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-20 22:50:03,013 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-20 22:50:03,015 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-20 22:50:03,344 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-20 22:50:03,344 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-20 22:50:03,346 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-20 22:50:03,346 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-20 22:50:03,366 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-20 22:50:03,366 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-20 22:50:03,366 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-20 22:50:03,366 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-20 22:50:03,377 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-20 22:50:03,377 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-20 22:50:03,377 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-20 22:50:03,377 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-20 22:50:03,379 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-20 22:50:03,379 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-20 22:50:03,379 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-20 22:50:03,382 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-20 22:50:03,382 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-20 22:50:03,382 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-20 22:50:03,405 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-20 22:50:03,535 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-20 22:50:03,554 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-20 22:50:03,564 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-20 22:50:03,574 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-20 22:50:03,583 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-20 22:50:03,583 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-20 22:50:03,583 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-20 22:50:03,619 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-20 22:50:03,619 INFO org.mortbay.log: jetty-6.1.26
2016-03-20 22:50:03,910 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-20 22:50:03,910 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-20 22:50:03,938 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-20 22:50:03,938 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-20 22:51:04,237 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2016-03-20 22:51:04,637 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=12&storageInfo=-63:851993283:0:CID-d96898ec-52b2-4521-8ac1-d6b10a73d42d
2016-03-20 22:51:04,730 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2016-03-20 22:51:05,347 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.11s at 0.00 KB/s
2016-03-20 22:51:05,347 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000012 size 557 bytes.
2016-03-20 22:51:05,362 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=13&endTxId=16&storageInfo=-63:851993283:0:CID-d96898ec-52b2-4521-8ac1-d6b10a73d42d
2016-03-20 22:51:05,370 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-03-20 22:51:05,371 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000013-0000000000000000016_0000000000012164980 size 0 bytes.
2016-03-20 22:51:05,456 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 4 INodes.
2016-03-20 22:51:05,503 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-03-20 22:51:05,505 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 12 from /tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000012
2016-03-20 22:51:05,505 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-03-20 22:51:05,511 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-20 22:51:05,515 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000013-0000000000000000016 expecting start txid #13
2016-03-20 22:51:05,515 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000013-0000000000000000016
2016-03-20 22:51:05,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000013-0000000000000000016 of size 298 edits # 4 loaded in 0 seconds
2016-03-20 22:51:05,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-vishal/dfs/namesecondary
2016-03-20 22:51:05,683 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 16 to namenode at http://localhost:50070 in 0.025 seconds
2016-03-20 22:51:05,684 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 724
2016-03-20 23:51:06,841 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2016-03-20 23:51:06,842 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=17&endTxId=27&storageInfo=-63:851993283:0:CID-d96898ec-52b2-4521-8ac1-d6b10a73d42d
2016-03-20 23:51:06,851 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-03-20 23:51:06,851 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000017-0000000000000000027_0000000000015766461 size 0 bytes.
2016-03-20 23:51:06,852 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-20 23:51:06,853 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000017-0000000000000000027 expecting start txid #17
2016-03-20 23:51:06,853 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000017-0000000000000000027
2016-03-20 23:51:06,913 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000017-0000000000000000027 of size 942 edits # 11 loaded in 0 seconds
2016-03-20 23:51:07,025 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 16
2016-03-20 23:51:07,030 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2016-03-20 23:51:07,060 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 27 to namenode at http://localhost:50070 in 0.024 seconds
2016-03-20 23:51:07,061 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1110
2016-03-21 00:51:07,919 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Found no edit logs to download on NN since txid 27
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:432)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 00:52:07,985 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 00:53:08,020 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 00:54:08,101 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 00:55:08,150 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 00:56:08,197 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 00:57:08,288 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 00:58:08,405 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 00:59:08,444 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:00:08,547 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:01:08,597 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:02:08,690 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:03:08,782 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:04:08,876 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:05:08,972 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:06:08,999 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:07:09,044 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:08:09,086 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:09:09,131 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:10:09,181 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:11:09,241 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:12:09,313 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:13:09,357 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:14:09,440 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:15:09,474 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:16:09,515 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:17:09,556 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:18:09,600 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:19:09,630 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:20:09,702 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:21:09,733 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:22:09,775 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:23:09,801 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:24:09,894 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:25:09,963 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:26:10,012 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:27:10,077 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:28:10,282 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:29:10,504 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:30:10,593 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:31:10,660 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:32:10,784 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:33:10,888 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:34:11,309 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:35:11,488 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:36:12,180 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:37:12,307 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:38:12,458 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:39:12,561 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:40:12,649 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:41:13,374 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:42:13,532 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:43:13,634 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:44:14,590 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:45:14,780 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:46:14,917 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:47:15,007 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:48:15,088 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:49:15,164 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:50:15,231 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:51:17,427 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:52:17,532 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:53:17,654 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:54:17,874 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:55:17,922 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:56:18,020 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:57:18,103 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:58:18,142 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 01:59:18,288 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:00:18,361 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:01:18,417 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:02:23,129 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:03:23,298 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:04:23,422 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:05:23,551 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:06:23,738 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:07:23,849 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:08:23,953 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:09:24,024 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:10:24,091 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:11:24,148 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:12:24,208 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:13:24,263 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:14:24,665 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:15:24,784 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:16:24,875 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:17:25,536 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:18:25,662 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:19:25,689 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:20:25,830 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:21:25,870 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:22:25,926 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:23:26,024 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:24:26,065 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:25:26,126 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:26:26,200 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:27:26,310 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:28:26,365 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:29:26,417 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:30:26,487 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:31:26,571 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:32:26,671 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:33:26,739 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:34:26,804 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:35:26,833 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:36:26,908 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:37:26,964 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:38:27,032 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:39:27,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:40:27,092 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:41:27,147 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:42:27,221 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:43:27,275 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:44:27,330 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:45:27,357 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:46:27,410 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:47:27,492 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:48:27,617 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:49:27,687 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:50:27,896 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:51:28,035 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:52:28,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:53:28,155 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:54:28,265 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:55:28,374 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:56:28,418 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:57:28,478 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:58:31,021 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 02:59:33,242 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:00:33,308 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:01:33,354 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:02:33,473 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:03:33,505 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:04:33,608 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:05:33,748 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:06:33,886 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:07:33,939 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:08:34,186 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:09:34,305 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:10:34,366 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:11:34,485 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:12:40,910 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:13:40,989 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:14:41,046 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:15:41,088 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:16:41,137 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:17:41,248 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:18:41,365 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:19:43,610 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:20:43,730 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:21:44,164 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:22:53,054 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:23:53,255 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:24:53,334 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:25:53,412 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:26:53,514 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:27:58,347 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:28:58,442 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:29:58,542 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:30:58,689 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:31:58,746 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:32:58,805 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:33:58,899 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:34:58,941 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:35:59,041 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:36:59,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:37:59,154 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:38:59,224 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:39:59,292 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:40:59,439 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:41:59,518 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:42:59,633 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:43:59,673 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:44:59,725 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:45:59,752 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:46:59,792 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:47:59,858 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:48:59,938 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:49:59,986 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:51:00,063 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:52:00,127 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:53:00,172 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:54:00,224 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:55:00,301 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:56:00,387 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:57:00,454 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:58:00,555 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 03:59:00,684 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:00:00,722 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:01:00,989 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:02:01,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:03:01,165 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:04:01,290 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:05:01,419 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:06:01,493 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:07:01,524 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:08:01,580 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:09:01,619 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:10:01,647 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:11:01,709 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:12:01,793 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:13:01,878 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:14:01,910 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:15:01,976 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:16:02,027 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:17:02,163 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:18:02,195 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:19:02,248 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:20:02,299 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:21:02,336 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:22:02,417 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:23:02,449 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:24:02,482 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:25:02,518 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:26:02,601 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:27:02,647 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:28:02,688 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:29:02,756 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:30:02,910 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:31:02,974 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:32:03,030 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:33:03,131 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:34:03,170 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:35:03,200 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:36:03,235 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:37:03,271 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:38:03,317 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:39:03,376 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:40:03,415 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:41:03,491 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:42:03,519 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:43:03,589 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:44:03,617 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:45:03,655 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:46:03,739 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:47:03,793 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:48:03,817 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:49:03,863 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:50:03,902 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:51:03,950 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:52:03,993 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:53:04,044 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:54:04,087 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:55:04,127 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:56:04,165 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:57:04,205 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:58:04,251 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 04:59:04,322 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:00:04,416 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:01:04,477 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:02:04,563 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:03:04,656 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:04:04,736 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:05:04,829 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:06:04,914 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:07:05,028 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:08:05,076 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:09:05,111 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:10:05,138 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:11:05,225 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:12:05,257 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:13:05,298 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:14:05,511 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:15:05,579 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:16:05,605 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:17:05,683 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:18:05,713 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:19:05,762 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:20:05,789 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:21:05,816 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:22:05,844 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:23:05,950 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:24:05,991 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:25:06,031 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:26:06,077 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:27:06,446 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:28:06,515 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:29:06,637 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:30:06,703 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:31:06,775 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:32:06,832 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:33:06,860 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:34:06,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:35:06,976 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:36:07,011 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:37:07,080 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:38:07,391 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:39:07,417 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:40:07,448 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:41:07,507 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:42:07,555 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:43:07,647 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:44:07,699 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:45:07,737 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:46:07,766 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:47:07,796 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771], [772,773]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:48:07,832 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771], [772,773], [774,775]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:49:07,946 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771], [772,773], [774,775], [776,777]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:50:08,076 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771], [772,773], [774,775], [776,777], [778,779]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:51:08,116 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771], [772,773], [774,775], [776,777], [778,779], [780,781]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:52:08,199 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771], [772,773], [774,775], [776,777], [778,779], [780,781], [782,783]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:53:08,242 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771], [772,773], [774,775], [776,777], [778,779], [780,781], [782,783], [784,785]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:54:08,319 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771], [772,773], [774,775], [776,777], [778,779], [780,781], [782,783], [784,785], [786,787]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:55:08,389 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771], [772,773], [774,775], [776,777], [778,779], [780,781], [782,783], [784,785], [786,787], [788,789]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:56:08,460 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771], [772,773], [774,775], [776,777], [778,779], [780,781], [782,783], [784,785], [786,787], [788,789], [790,791]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 05:57:08,485 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Bad edit log manifest (expected txid = 28: [[150,151], [152,153], [154,155], [156,157], [158,159], [160,161], [162,163], [164,165], [166,167], [168,169], [170,171], [172,173], [174,175], [176,177], [178,179], [180,181], [182,183], [184,185], [186,187], [188,189], [190,191], [192,193], [194,195], [196,197], [198,199], [200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245], [246,247], [248,249], [250,251], [252,253], [254,255], [256,257], [258,259], [260,261], [262,263], [264,265], [266,267], [268,269], [270,271], [272,275], [276,277], [278,279], [280,281], [282,283], [284,285], [286,288], [289,290], [291,292], [293,294], [295,296], [297,298], [299,300], [301,302], [303,304], [305,306], [307,308], [309,310], [311,312], [313,314], [315,316], [317,318], [319,320], [321,322], [323,324], [325,326], [327,328], [329,330], [331,332], [333,334], [335,336], [337,338], [339,340], [341,342], [343,344], [345,348], [349,350], [351,352], [353,357], [358,360], [361,362], [363,364], [365,366], [367,370], [371,372], [373,375], [376,379], [380,382], [383,384], [385,387], [388,389], [390,391], [392,393], [394,395], [396,397], [398,399], [400,401], [402,403], [404,405], [406,407], [408,409], [410,411], [412,413], [414,415], [416,417], [418,419], [420,421], [422,423], [424,425], [426,427], [428,429], [430,431], [432,433], [434,435], [436,437], [438,439], [440,441], [442,443], [444,445], [446,447], [448,449], [450,451], [452,453], [454,455], [456,457], [458,459], [460,461], [462,463], [464,465], [466,467], [468,469], [470,471], [472,473], [474,475], [476,477], [478,479], [480,483], [484,486], [487,488], [489,493], [494,496], [497,498], [499,500], [501,502], [503,504], [505,506], [507,508], [509,510], [511,512], [513,514], [515,516], [517,518], [519,520], [521,522], [523,524], [525,530], [531,532], [533,534], [535,536], [537,538], [539,540], [541,542], [543,544], [545,546], [547,548], [549,550], [551,552], [553,554], [555,556], [557,558], [559,560], [561,562], [563,564], [565,566], [567,568], [569,570], [571,572], [573,574], [575,576], [577,578], [579,580], [581,582], [583,584], [585,586], [587,588], [589,590], [591,592], [593,594], [595,596], [597,598], [599,600], [601,602], [603,604], [605,606], [607,608], [609,610], [611,612], [613,617], [618,620], [621,622], [623,624], [625,626], [627,628], [629,630], [631,632], [633,634], [635,636], [637,638], [639,640], [641,642], [643,644], [645,646], [647,648], [649,650], [651,652], [653,654], [655,656], [657,658], [659,660], [661,662], [663,664], [665,666], [667,668], [669,670], [671,672], [673,676], [677,678], [679,680], [681,682], [683,684], [685,686], [687,688], [689,690], [691,692], [693,694], [695,696], [697,698], [699,700], [701,702], [703,705], [706,707], [708,709], [710,711], [712,713], [714,715], [716,717], [718,719], [720,721], [722,723], [724,725], [726,727], [728,729], [730,731], [732,733], [734,735], [736,737], [738,739], [740,741], [742,743], [744,745], [746,747], [748,749], [750,751], [752,753], [754,755], [756,757], [758,759], [760,761], [762,763], [764,765], [766,767], [768,769], [770,771], [772,773], [774,775], [776,777], [778,779], [780,781], [782,783], [784,785], [786,787], [788,789], [790,791], [792,793]]
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.downloadCheckpointFiles(SecondaryNameNode.java:438)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:540)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 06:11:23,475 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-21 06:11:23,512 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-21 06:11:24,449 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-21 06:11:24,570 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-21 06:11:24,570 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-21 06:11:24,859 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 4040@vishal-VirtualBox
2016-03-21 06:11:24,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-21 06:11:24,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-21 06:11:24,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-21 06:11:24,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-21 06:11:24,944 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-21 06:11:24,946 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 21 06:11:24
2016-03-21 06:11:24,954 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-21 06:11:24,954 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 06:11:24,955 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-21 06:11:24,955 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-21 06:11:24,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-21 06:11:24,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-21 06:11:24,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-21 06:11:24,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-21 06:11:24,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-21 06:11:24,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-21 06:11:24,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-21 06:11:24,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-21 06:11:24,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-21 06:11:24,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-21 06:11:24,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-21 06:11:24,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-21 06:11:24,993 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-21 06:11:25,301 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-21 06:11:25,301 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 06:11:25,302 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-21 06:11:25,302 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-21 06:11:25,308 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-21 06:11:25,308 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-21 06:11:25,309 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-21 06:11:25,309 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-21 06:11:25,322 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-21 06:11:25,322 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 06:11:25,323 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-21 06:11:25,323 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-21 06:11:25,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-21 06:11:25,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-21 06:11:25,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-21 06:11:25,331 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-21 06:11:25,331 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-21 06:11:25,331 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-21 06:11:25,349 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-21 06:11:25,458 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-21 06:11:25,471 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-21 06:11:25,475 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-21 06:11:25,480 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-21 06:11:25,490 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-21 06:11:25,490 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-21 06:11:25,490 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-21 06:11:25,543 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-21 06:11:25,544 INFO org.mortbay.log: jetty-6.1.26
2016-03-21 06:11:25,805 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-21 06:11:25,806 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-21 06:11:25,833 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-21 06:11:25,833 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-21 06:49:27,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:49:28,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:49:29,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:49:30,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:49:31,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:49:32,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:49:33,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:49:34,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:49:35,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:49:36,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:49:36,593 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-21 06:50:37,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:50:38,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:50:39,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:50:40,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:50:41,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:50:42,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:50:43,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:50:44,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:50:45,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:50:46,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:50:46,652 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-21 06:51:47,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:51:48,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:51:49,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:51:50,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:51:51,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:51:52,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:51:53,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:51:54,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:51:55,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:51:56,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:51:56,663 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-21 06:52:57,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:52:58,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:52:59,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:53:00,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:53:01,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:53:02,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:53:03,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:53:04,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:53:05,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:53:06,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:53:06,687 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-21 06:54:07,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:54:08,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:54:09,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:54:10,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:54:11,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:54:12,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:54:13,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:54:14,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:54:15,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:54:16,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-03-21 06:54:16,706 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From vishal-VirtualBox/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)
	at org.apache.hadoop.ipc.Client.call(Client.java:1451)
	... 17 more
2016-03-21 06:55:15,945 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-21 06:55:15,951 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-21 06:57:36,471 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-21 06:57:36,528 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-21 06:57:38,586 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-21 06:57:39,027 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-21 06:57:39,028 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-21 06:57:39,881 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 3046@vishal-VirtualBox
2016-03-21 06:57:39,897 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-21 06:57:39,897 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-21 06:57:40,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-21 06:57:40,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-21 06:57:40,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-21 06:57:40,086 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 21 06:57:40
2016-03-21 06:57:40,115 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-21 06:57:40,115 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 06:57:40,116 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-21 06:57:40,116 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-21 06:57:40,180 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-21 06:57:40,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-21 06:57:40,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-21 06:57:40,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-21 06:57:40,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-21 06:57:40,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-21 06:57:40,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-21 06:57:40,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-21 06:57:40,190 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-21 06:57:40,190 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-21 06:57:40,190 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-21 06:57:40,190 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-21 06:57:40,217 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-21 06:57:41,245 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-21 06:57:41,245 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 06:57:41,264 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-21 06:57:41,264 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-21 06:57:41,283 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-21 06:57:41,283 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-21 06:57:41,283 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-21 06:57:41,284 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-21 06:57:41,324 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-21 06:57:41,324 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 06:57:41,324 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-21 06:57:41,324 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-21 06:57:41,333 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-21 06:57:41,341 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-21 06:57:41,341 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-21 06:57:41,354 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-21 06:57:41,354 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-21 06:57:41,354 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-21 06:57:41,426 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-21 06:57:41,855 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-21 06:57:41,887 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-21 06:57:41,918 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-21 06:57:41,936 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-21 06:57:41,971 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-21 06:57:41,972 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-21 06:57:41,972 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-21 06:57:42,088 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-21 06:57:42,089 INFO org.mortbay.log: jetty-6.1.26
2016-03-21 06:57:42,748 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-21 06:57:42,748 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-21 06:57:42,775 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-21 06:57:42,775 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-21 07:55:44,284 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2016-03-21 07:55:44,585 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:1838749044:0:CID-8279c9c3-8109-4a8c-9a8e-ccd16aaca05e
2016-03-21 07:55:44,671 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2016-03-21 07:55:45,214 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.10s at 0.00 KB/s
2016-03-21 07:55:45,214 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 353 bytes.
2016-03-21 07:55:45,227 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=26&storageInfo=-63:1838749044:0:CID-8279c9c3-8109-4a8c-9a8e-ccd16aaca05e
2016-03-21 07:55:45,236 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 500.00 KB/s
2016-03-21 07:55:45,237 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000026_0000000000003623216 size 0 bytes.
2016-03-21 07:55:45,303 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-03-21 07:55:45,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-03-21 07:55:45,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000000
2016-03-21 07:55:45,355 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-03-21 07:55:45,360 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-21 07:55:45,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000026 expecting start txid #1
2016-03-21 07:55:45,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000026
2016-03-21 07:55:45,425 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000026 of size 2781 edits # 26 loaded in 0 seconds
2016-03-21 07:55:45,487 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-vishal/dfs/namesecondary
2016-03-21 07:55:45,545 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 26 to namenode at http://localhost:50070 in 0.051 seconds
2016-03-21 07:55:45,546 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 557
2016-03-21 12:21:59,736 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-21 12:21:59,751 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-21 12:46:21,998 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-21 12:46:22,055 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-21 12:46:25,284 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-21 12:46:25,571 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-21 12:46:25,571 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-21 12:46:26,219 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 3257@vishal-VirtualBox
2016-03-21 12:46:26,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-21 12:46:26,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-21 12:46:26,340 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-21 12:46:26,340 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-21 12:46:26,345 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-21 12:46:26,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 21 12:46:26
2016-03-21 12:46:26,356 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-21 12:46:26,356 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 12:46:26,357 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-21 12:46:26,357 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-21 12:46:26,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-21 12:46:26,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-21 12:46:26,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-21 12:46:26,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-21 12:46:26,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-21 12:46:26,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-21 12:46:26,410 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-21 12:46:26,410 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-21 12:46:26,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-21 12:46:26,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-21 12:46:26,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-21 12:46:26,414 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-21 12:46:26,416 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-21 12:46:27,077 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-21 12:46:27,089 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 12:46:27,090 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-21 12:46:27,090 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-21 12:46:27,101 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-21 12:46:27,102 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-21 12:46:27,102 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-21 12:46:27,102 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-21 12:46:27,129 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-21 12:46:27,129 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 12:46:27,131 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-21 12:46:27,131 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-21 12:46:27,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-21 12:46:27,142 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-21 12:46:27,142 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-21 12:46:27,145 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-21 12:46:27,145 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-21 12:46:27,145 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-21 12:46:27,188 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-21 12:46:27,455 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-21 12:46:27,485 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-21 12:46:27,504 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-21 12:46:27,514 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-21 12:46:27,537 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-21 12:46:27,537 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-21 12:46:27,538 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-21 12:46:27,795 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-21 12:46:27,795 INFO org.mortbay.log: jetty-6.1.26
2016-03-21 12:46:28,280 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-21 12:46:28,280 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-21 12:46:28,290 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-21 12:46:28,290 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-21 13:43:24,927 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2016-03-21 13:43:25,297 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:1246822268:0:CID-99957fad-eb72-47dc-8229-158e49a064c0
2016-03-21 13:43:25,498 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2016-03-21 13:43:26,481 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.14s at 0.00 KB/s
2016-03-21 13:43:26,481 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 353 bytes.
2016-03-21 13:43:26,494 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=7&storageInfo=-63:1246822268:0:CID-99957fad-eb72-47dc-8229-158e49a064c0
2016-03-21 13:43:26,501 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-03-21 13:43:26,502 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000007_0000000000003643956 size 0 bytes.
2016-03-21 13:43:26,583 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-03-21 13:43:26,667 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-03-21 13:43:26,668 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000000
2016-03-21 13:43:26,668 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-03-21 13:43:26,672 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-21 13:43:26,677 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000007 expecting start txid #1
2016-03-21 13:43:26,677 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000007
2016-03-21 13:43:26,717 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000007 of size 531 edits # 7 loaded in 0 seconds
2016-03-21 13:43:26,775 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-vishal/dfs/namesecondary
2016-03-21 13:43:26,840 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 7 to namenode at http://localhost:50070 in 0.056 seconds
2016-03-21 13:43:26,841 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 724
2016-03-21 16:40:09,171 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2016-03-21 16:40:09,174 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=8&endTxId=24&storageInfo=-63:1246822268:0:CID-99957fad-eb72-47dc-8229-158e49a064c0
2016-03-21 16:40:09,192 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 142.86 KB/s
2016-03-21 16:40:09,193 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000008-0000000000000000024_0000000000007245200 size 0 bytes.
2016-03-21 16:40:09,193 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-21 16:40:09,193 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000008-0000000000000000024 expecting start txid #8
2016-03-21 16:40:09,193 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000008-0000000000000000024
2016-03-21 16:40:09,223 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000008-0000000000000000024 of size 1740 edits # 17 loaded in 0 seconds
2016-03-21 16:40:09,241 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 7
2016-03-21 16:40:09,241 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2016-03-21 16:40:09,272 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 24 to namenode at http://localhost:50070 in 0.018 seconds
2016-03-21 16:40:09,272 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 917
2016-03-21 17:40:10,178 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2016-03-21 17:40:10,192 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=25&endTxId=27&storageInfo=-63:1246822268:0:CID-99957fad-eb72-47dc-8229-158e49a064c0
2016-03-21 17:40:10,211 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2016-03-21 17:40:10,211 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000025-0000000000000000027_0000000000010846218 size 0 bytes.
2016-03-21 17:40:10,212 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-21 17:40:10,212 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000025-0000000000000000027 expecting start txid #25
2016-03-21 17:40:10,212 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000025-0000000000000000027
2016-03-21 17:40:10,213 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000025-0000000000000000027 of size 144 edits # 3 loaded in 0 seconds
2016-03-21 17:40:10,234 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 24
2016-03-21 17:40:10,235 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000007, cpktTxId=0000000000000000007)
2016-03-21 17:40:10,254 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 27 to namenode at http://localhost:50070 in 0.017 seconds
2016-03-21 17:40:10,254 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 750
2016-03-21 18:03:39,731 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-21 18:03:39,733 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-21 18:05:08,052 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-21 18:05:08,075 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-21 18:05:09,064 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-21 18:05:09,199 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-21 18:05:09,199 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-21 18:05:09,484 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 10487@vishal-VirtualBox
2016-03-21 18:05:09,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-21 18:05:09,599 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-21 18:05:09,669 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-21 18:05:09,669 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-21 18:05:09,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-21 18:05:09,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 21 18:05:09
2016-03-21 18:05:09,680 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-21 18:05:09,680 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 18:05:09,681 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-21 18:05:09,682 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-21 18:05:09,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-21 18:05:09,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-21 18:05:09,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-21 18:05:09,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-21 18:05:09,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-21 18:05:09,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-21 18:05:09,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-21 18:05:09,703 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-21 18:05:09,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-21 18:05:09,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-21 18:05:09,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-21 18:05:09,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-21 18:05:09,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-21 18:05:10,098 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-21 18:05:10,098 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 18:05:10,102 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-21 18:05:10,102 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-21 18:05:10,102 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-21 18:05:10,102 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-21 18:05:10,102 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-21 18:05:10,103 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-21 18:05:10,117 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-21 18:05:10,117 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 18:05:10,118 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-21 18:05:10,118 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-21 18:05:10,131 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-21 18:05:10,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-21 18:05:10,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-21 18:05:10,135 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-21 18:05:10,135 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-21 18:05:10,135 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-21 18:05:10,156 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-21 18:05:10,260 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-21 18:05:10,278 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-21 18:05:10,285 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-21 18:05:10,298 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-21 18:05:10,305 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-21 18:05:10,305 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-21 18:05:10,305 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-21 18:05:10,333 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-21 18:05:10,333 INFO org.mortbay.log: jetty-6.1.26
2016-03-21 18:05:10,576 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-21 18:05:10,576 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-21 18:05:10,580 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-21 18:05:10,580 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-21 18:06:11,078 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:07:11,157 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:08:11,285 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:09:11,390 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:10:11,495 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:11:11,594 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:12:11,648 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:13:11,774 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:14:12,122 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:15:12,194 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:16:12,257 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:17:12,395 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:18:12,514 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:19:12,623 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:20:12,719 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:21:12,829 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:22:12,900 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:23:12,969 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:24:13,047 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:25:13,201 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:26:13,257 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:27:13,299 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:28:13,346 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:29:13,396 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:30:13,510 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:31:13,605 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:32:13,648 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:33:13,744 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:34:13,859 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:35:13,948 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:36:14,003 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:37:14,103 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:38:14,223 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:39:14,364 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:40:14,432 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:41:14,558 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:42:14,622 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:43:14,686 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:44:14,812 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:45:14,903 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:46:14,999 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:47:15,051 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:48:15,105 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:49:15,206 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:50:15,326 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:51:15,471 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:52:15,572 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:53:15,706 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:54:15,787 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:55:15,930 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:56:16,074 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:57:16,156 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:58:16,262 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 18:59:16,363 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:00:16,492 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:01:16,554 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:02:16,635 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:03:16,736 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:04:16,890 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:05:17,043 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:06:17,416 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:07:17,482 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:08:17,541 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:09:17,583 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:10:17,661 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:11:17,775 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:12:17,843 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:13:17,927 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:14:18,016 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:15:18,114 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:16:18,194 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:17:18,356 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:18:18,452 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:19:18,549 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:20:18,678 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:21:18,777 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:22:18,891 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:23:18,951 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:24:19,047 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:25:19,133 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:26:19,218 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:27:19,382 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:28:19,470 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:29:19,557 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:30:19,704 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:31:19,845 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:32:19,943 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:33:20,090 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:34:20,239 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:35:20,359 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:36:20,426 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:37:20,504 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:38:20,570 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:39:20,634 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:40:20,737 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:41:20,812 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:42:20,860 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:43:20,951 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:44:21,082 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:45:21,136 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:46:21,215 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:47:21,250 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:48:21,297 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:49:21,336 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:50:21,416 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:51:21,491 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:52:21,648 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:53:21,749 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:54:21,818 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:55:21,899 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:56:22,025 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:57:22,145 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:58:22,231 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 19:59:22,308 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:00:22,488 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:01:22,614 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:02:22,741 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:03:22,859 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:04:22,973 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:05:23,057 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:06:23,147 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:07:23,284 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:08:23,426 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:09:23,530 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:10:23,671 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:11:23,800 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:12:23,914 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:13:23,973 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:14:24,053 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:15:24,088 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:16:24,164 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:17:24,256 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:18:24,341 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:19:24,390 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:20:24,415 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:21:24,513 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:22:24,585 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:23:24,767 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:24:24,915 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:25:25,005 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:26:25,116 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:27:25,181 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:28:25,283 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:29:25,387 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:30:25,467 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:31:25,589 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:32:25,801 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:33:25,955 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:34:26,030 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:35:26,068 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:36:26,092 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:37:26,135 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:38:26,209 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:39:26,262 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:40:26,339 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 964300843 cTime = 0 ; clusterId = CID-e127bd84-6d62-41a4-8418-697c99bd7d2b ; blockpoolId = BP-460232460-127.0.1.1-1458601478826.
Expecting respectively: -63; 1246822268; 0; CID-99957fad-eb72-47dc-8229-158e49a064c0; BP-1750672334-127.0.1.1-1458582352899.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:415)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:745)
2016-03-21 20:41:05,902 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-21 20:41:05,903 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-21 21:01:05,701 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-21 21:01:05,748 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-21 21:01:06,717 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-21 21:01:06,856 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-21 21:01:06,856 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-21 21:01:07,158 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 3132@vishal-VirtualBox
2016-03-21 21:01:07,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-21 21:01:07,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-21 21:01:07,270 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-21 21:01:07,270 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-21 21:01:07,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-21 21:01:07,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 21 21:01:07
2016-03-21 21:01:07,283 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-21 21:01:07,283 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 21:01:07,290 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-21 21:01:07,290 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-21 21:01:07,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-21 21:01:07,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-21 21:01:07,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-21 21:01:07,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-21 21:01:07,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-21 21:01:07,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-21 21:01:07,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-21 21:01:07,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-21 21:01:07,316 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-21 21:01:07,316 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-21 21:01:07,317 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-21 21:01:07,317 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-21 21:01:07,325 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-21 21:01:07,622 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-21 21:01:07,622 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 21:01:07,623 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-21 21:01:07,623 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-21 21:01:07,630 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-21 21:01:07,630 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-21 21:01:07,630 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-21 21:01:07,630 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-21 21:01:07,641 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-21 21:01:07,641 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-21 21:01:07,642 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-21 21:01:07,642 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-21 21:01:07,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-21 21:01:07,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-21 21:01:07,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-21 21:01:07,652 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-21 21:01:07,652 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-21 21:01:07,652 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-21 21:01:07,671 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-21 21:01:07,817 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-21 21:01:07,834 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-21 21:01:07,844 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-21 21:01:07,849 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-21 21:01:07,858 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-21 21:01:07,859 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-21 21:01:07,859 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-21 21:01:07,888 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-21 21:01:07,889 INFO org.mortbay.log: jetty-6.1.26
2016-03-21 21:01:08,116 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-21 21:01:08,116 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-21 21:01:08,120 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-21 21:01:08,120 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-21 21:50:09,317 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2016-03-21 21:50:09,585 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=324&storageInfo=-63:964300843:0:CID-e127bd84-6d62-41a4-8418-697c99bd7d2b
2016-03-21 21:50:09,656 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2016-03-21 21:50:10,255 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.16s at 0.00 KB/s
2016-03-21 21:50:10,255 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000324 size 812 bytes.
2016-03-21 21:50:10,268 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=325&endTxId=326&storageInfo=-63:964300843:0:CID-e127bd84-6d62-41a4-8418-697c99bd7d2b
2016-03-21 21:50:10,276 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-03-21 21:50:10,276 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000325-0000000000000000326_0000000000003619415 size 0 bytes.
2016-03-21 21:50:10,348 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 8 INodes.
2016-03-21 21:50:10,410 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-03-21 21:50:10,410 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 324 from /tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000324
2016-03-21 21:50:10,410 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-03-21 21:50:10,419 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-21 21:50:10,426 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000325-0000000000000000326 expecting start txid #325
2016-03-21 21:50:10,426 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000325-0000000000000000326
2016-03-21 21:50:10,451 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000325-0000000000000000326 of size 42 edits # 2 loaded in 0 seconds
2016-03-21 21:50:10,514 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-vishal/dfs/namesecondary
2016-03-21 21:50:10,585 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 326 to namenode at http://localhost:50070 in 0.06 seconds
2016-03-21 21:50:10,585 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 812
2016-03-21 22:50:12,654 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2016-03-21 22:50:12,800 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=327&endTxId=328&storageInfo=-63:964300843:0:CID-e127bd84-6d62-41a4-8418-697c99bd7d2b
2016-03-21 22:50:13,375 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.13s at 0.00 KB/s
2016-03-21 22:50:13,376 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000327-0000000000000000328_0000000000007221943 size 0 bytes.
2016-03-21 22:50:13,383 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-21 22:50:13,395 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000327-0000000000000000328 expecting start txid #327
2016-03-21 22:50:13,449 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000327-0000000000000000328
2016-03-21 22:50:13,544 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000327-0000000000000000328 of size 42 edits # 2 loaded in 0 seconds
2016-03-21 22:50:14,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 326
2016-03-21 22:50:14,183 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000324, cpktTxId=0000000000000000324)
2016-03-21 22:50:15,570 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 328 to namenode at http://localhost:50070 in 1.235 seconds
2016-03-21 22:50:15,571 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 812
2016-03-21 23:50:17,298 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2016-03-21 23:50:17,331 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=329&endTxId=330&storageInfo=-63:964300843:0:CID-e127bd84-6d62-41a4-8418-697c99bd7d2b
2016-03-21 23:50:17,339 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-03-21 23:50:17,339 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000329-0000000000000000330_0000000000010826478 size 0 bytes.
2016-03-21 23:50:17,339 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-21 23:50:17,339 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000329-0000000000000000330 expecting start txid #329
2016-03-21 23:50:17,339 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000329-0000000000000000330
2016-03-21 23:50:17,339 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000329-0000000000000000330 of size 42 edits # 2 loaded in 0 seconds
2016-03-21 23:50:17,360 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 328
2016-03-21 23:50:17,360 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000326, cpktTxId=0000000000000000326)
2016-03-21 23:50:17,433 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 330 to namenode at http://localhost:50070 in 0.042 seconds
2016-03-21 23:50:17,436 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 812
2016-03-22 00:50:18,344 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2016-03-22 00:50:18,345 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=331&endTxId=332&storageInfo=-63:964300843:0:CID-e127bd84-6d62-41a4-8418-697c99bd7d2b
2016-03-22 00:50:18,370 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 0.00 KB/s
2016-03-22 00:50:18,370 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000331-0000000000000000332_0000000000014427492 size 0 bytes.
2016-03-22 00:50:18,371 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-22 00:50:18,371 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000331-0000000000000000332 expecting start txid #331
2016-03-22 00:50:18,371 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000331-0000000000000000332
2016-03-22 00:50:18,372 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000331-0000000000000000332 of size 42 edits # 2 loaded in 0 seconds
2016-03-22 00:50:18,394 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 330
2016-03-22 00:50:18,394 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000328, cpktTxId=0000000000000000328)
2016-03-22 00:50:18,448 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 332 to namenode at http://localhost:50070 in 0.043 seconds
2016-03-22 00:50:18,448 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 812
2016-03-22 01:50:19,480 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2016-03-22 01:50:19,481 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=333&endTxId=334&storageInfo=-63:964300843:0:CID-e127bd84-6d62-41a4-8418-697c99bd7d2b
2016-03-22 01:50:19,493 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-03-22 01:50:19,493 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000333-0000000000000000334_0000000000018028628 size 0 bytes.
2016-03-22 01:50:19,508 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-22 01:50:19,509 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000333-0000000000000000334 expecting start txid #333
2016-03-22 01:50:19,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000333-0000000000000000334
2016-03-22 01:50:19,514 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000333-0000000000000000334 of size 42 edits # 2 loaded in 0 seconds
2016-03-22 01:50:19,546 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 332
2016-03-22 01:50:19,546 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000330, cpktTxId=0000000000000000330)
2016-03-22 01:50:19,608 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 334 to namenode at http://localhost:50070 in 0.047 seconds
2016-03-22 01:50:19,608 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 812
2016-03-22 02:34:47,814 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-22 02:34:48,393 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-22 04:26:10,733 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-22 04:26:10,808 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-22 04:26:11,848 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-22 04:26:12,022 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-22 04:26:12,022 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-22 04:26:12,511 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 3269@vishal-VirtualBox
2016-03-22 04:26:12,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-22 04:26:12,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-22 04:26:12,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-22 04:26:12,567 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-22 04:26:12,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-22 04:26:12,570 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 22 04:26:12
2016-03-22 04:26:12,611 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-22 04:26:12,611 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-22 04:26:12,613 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-22 04:26:12,613 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-22 04:26:12,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-22 04:26:12,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-22 04:26:12,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-22 04:26:12,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-22 04:26:12,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-22 04:26:12,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-22 04:26:12,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-22 04:26:12,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-22 04:26:12,759 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-22 04:26:12,759 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-22 04:26:12,759 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-22 04:26:12,759 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-22 04:26:12,763 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-22 04:26:13,066 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-22 04:26:13,066 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-22 04:26:13,072 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-22 04:26:13,072 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-22 04:26:13,078 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-22 04:26:13,078 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-22 04:26:13,078 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-22 04:26:13,078 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-22 04:26:13,088 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-22 04:26:13,089 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-22 04:26:13,089 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-22 04:26:13,089 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-22 04:26:13,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-22 04:26:13,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-22 04:26:13,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-22 04:26:13,103 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-22 04:26:13,104 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-22 04:26:13,104 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-22 04:26:13,122 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-22 04:26:13,251 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-22 04:26:13,268 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-22 04:26:13,275 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-22 04:26:13,285 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-22 04:26:13,293 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-22 04:26:13,293 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-22 04:26:13,293 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-22 04:26:13,325 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-22 04:26:13,325 INFO org.mortbay.log: jetty-6.1.26
2016-03-22 04:26:13,579 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-22 04:26:13,579 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-22 04:26:13,595 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-22 04:26:13,596 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2016-03-22 04:59:14,705 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2016-03-22 04:59:15,011 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=335&storageInfo=-63:964300843:0:CID-e127bd84-6d62-41a4-8418-697c99bd7d2b
2016-03-22 04:59:15,106 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2016-03-22 04:59:15,640 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.10s at 0.00 KB/s
2016-03-22 04:59:15,640 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000335 size 812 bytes.
2016-03-22 04:59:15,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=336&endTxId=348&storageInfo=-63:964300843:0:CID-e127bd84-6d62-41a4-8418-697c99bd7d2b
2016-03-22 04:59:15,661 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 250.00 KB/s
2016-03-22 04:59:15,661 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000336-0000000000000000348_0000000000003601289 size 0 bytes.
2016-03-22 04:59:15,728 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 8 INodes.
2016-03-22 04:59:15,783 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-03-22 04:59:15,783 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 335 from /tmp/hadoop-vishal/dfs/namesecondary/current/fsimage_0000000000000000335
2016-03-22 04:59:15,783 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-03-22 04:59:15,788 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2016-03-22 04:59:15,792 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000336-0000000000000000348 expecting start txid #336
2016-03-22 04:59:15,792 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000336-0000000000000000348
2016-03-22 04:59:15,831 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-vishal/dfs/namesecondary/current/edits_0000000000000000336-0000000000000000348 of size 1372 edits # 13 loaded in 0 seconds
2016-03-22 04:59:15,903 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-vishal/dfs/namesecondary
2016-03-22 04:59:15,971 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 348 to namenode at http://localhost:50070 in 0.06 seconds
2016-03-22 04:59:15,971 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 979
2016-03-22 10:11:12,429 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2016-03-22 10:11:12,437 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at vishal-VirtualBox/127.0.1.1
************************************************************/
2016-03-23 04:16:44,994 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = vishal-VirtualBox/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41; compiled by 'jenkins' on 2016-01-26T00:08Z
STARTUP_MSG:   java = 1.8.0_74
************************************************************/
2016-03-23 04:16:45,030 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-03-23 04:16:46,256 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-03-23 04:16:46,440 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-03-23 04:16:46,440 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2016-03-23 04:16:46,840 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-vishal/dfs/namesecondary/in_use.lock acquired by nodename 3067@vishal-VirtualBox
2016-03-23 04:16:46,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-03-23 04:16:46,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-03-23 04:16:46,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-03-23 04:16:46,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-03-23 04:16:46,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-03-23 04:16:46,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Mar 23 04:16:46
2016-03-23 04:16:46,941 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-03-23 04:16:46,941 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-23 04:16:46,943 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2016-03-23 04:16:46,943 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-03-23 04:16:46,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-03-23 04:16:46,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2016-03-23 04:16:46,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-03-23 04:16:46,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-03-23 04:16:46,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-03-23 04:16:46,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-03-23 04:16:46,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-03-23 04:16:46,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-03-23 04:16:46,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = vishal (auth:SIMPLE)
2016-03-23 04:16:46,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-03-23 04:16:46,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-03-23 04:16:46,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-03-23 04:16:46,980 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-03-23 04:16:47,413 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-03-23 04:16:47,413 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-23 04:16:47,418 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2016-03-23 04:16:47,418 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-03-23 04:16:47,431 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-03-23 04:16:47,431 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-03-23 04:16:47,431 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-03-23 04:16:47,431 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-03-23 04:16:47,443 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-03-23 04:16:47,443 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-03-23 04:16:47,443 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2016-03-23 04:16:47,444 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-03-23 04:16:47,445 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-03-23 04:16:47,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-03-23 04:16:47,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-03-23 04:16:47,453 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-03-23 04:16:47,453 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-03-23 04:16:47,453 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-03-23 04:16:47,477 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2016-03-23 04:16:47,662 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-03-23 04:16:47,673 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-03-23 04:16:47,684 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2016-03-23 04:16:47,692 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-03-23 04:16:47,699 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2016-03-23 04:16:47,699 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-03-23 04:16:47,699 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-03-23 04:16:47,737 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2016-03-23 04:16:47,738 INFO org.mortbay.log: jetty-6.1.26
2016-03-23 04:16:48,031 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2016-03-23 04:16:48,031 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2016-03-23 04:16:48,034 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2016-03-23 04:16:48,034 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
